---
documentclass: article
fontsize: 12pt
date: "`r Sys.Date()`"
output: 
  bookdown::pdf_document2: 
    toc: false
    latex_engine: xelatex
    fig_caption: yes
    includes:
      in_header: preamble.sty
      before_body: titlepage.sty
bibliography: references.bib  
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(haven) # to read SAS files
library(kableExtra)
library(qwraps2)
library(rprojroot)
library(patchwork)
library(psych)
library(gtools)
library(ordinal)
library(visdat)#visualize missingness
library(mice)
knitr::opts_chunk$set(echo = TRUE)
```

```{r load, include=FALSE, message=FALSE, warning=FALSE}
trichotomization <- c(-100, 6, 25, 120)
data <- read_sas(find_root_file("data/hearing500lr.sas7bdat",
                                criterion = has_file("LDA.Rproj"))) %>%
  mutate(side = as.factor(side),
         side_integer = as.integer(side),
         TIME_discrete = round(TIME),
         id = as.factor(id),
         id_integer = as.integer(id),
         age_measurement = age + TIME,
         age_scale = unname(scale(age, center = TRUE, scale = TRUE)),
         age_discrete = cut(age,
                            breaks = c(0,30,50,70,100),
                            labels = c("<30", "30-50", "50-70",">70")),
         y_discrete = factor(as.factor(cut(y,
                          breaks = trichotomization,
                          labels = c("Excellent", "Normal", "Hearing loss"))),
                          levels = c("Excellent", "Normal", "Hearing loss"),
                          ordered = TRUE),
         y_integer = as.integer(y_discrete),
         learning = 1*(TIME == 0)) %>%
  arrange(id)
subject_characteristics <- data %>%
  group_by(id) %>%
  summarize(age = first(age),
            age_scale = first(age_scale),
            age_discrete = first(age_discrete),
            id_integer = first(id_integer)) %>%
  ungroup()
  
data_grid <- expand.grid(id = unique(data$id),
                         TIME_discrete = 0:max(data$TIME_discrete),
                         side = unique(data$side)) %>%
  left_join(data %>% dplyr::select(-age, -age_scale, -age_discrete, 
                                   -id_integer)) %>%
  mutate(R = is.na(y), # R denotes missingness
         learning = (TIME_discrete == 0)) %>%
  left_join(subject_characteristics, by = c("id" = "id")) #add the subject characteristics back in)
```

# Introduction

This report assesses the evolution of hearing thresholds over time for a sample of `r nlevels(data$id)` healthy male volunteers. The data originates from the famous Baltimore Longitudinal Study of Aging (BLSA). Previous research showed a change in hearing threshold for all age groups but especially the older population [@doi:10.1121/1.399731]. In this report, we will especially take care of missingness in the data.

First, the *TIME* variable is rounded to the nearest integer value. As such, we aim to balance the dataset with equally-spaced time instances when hearing thresholds are measured. 

Hearing thresholds will be explored, both as a continuous variable and as a trichotomized (ordinal) variable with the following three levels:

- $\leq$ 6 dB: Excellent hearing
- over 6 and $\leq$ 25 dB: Normal hearing
- $\geq$ 26 dB: Hearing loss

## Missingness exploration
```{r Missingnessprep, include=FALSE, message=FALSE, warning=FALSE}
data_by_id_time <- data_grid %>% 
  group_by(id, TIME_discrete) %>%
  summarize(n = sum(!is.na(y_discrete))) %>%
  ungroup()
```

After discretizing the *TIME* variable, we consider a subject to be missing at a certain time instance if there is no measurement for that subject at that time. It should be noted that, if the subject is not missing (`r round((1-sum(data_by_id_time$n==0)/nrow(data_by_id_time))*100,2)`% of TIME-subject instances), we usually (`r round((sum(data_by_id_time$n==2)/nrow(data_by_id_time))*100,2)`% of TIME-subject instances) have two measurements (one for each ear) at each time instance. In fact, the average number of measurements per subject at each time instance is `r round(mean(data_by_id_time$n),2)`, and maximum `r round(max(data_by_id_time$n),2)`. 

Figure \@ref(fig:Missingness) was created using the *visdat* package. It shows all subjects, ordered from youngest (in the top) to oldest (in the bottom) and whether or not their data is missing at a certain time instance (on the x-axis). The percentages on top shows the percentage of missingness at each time instance. It is clear from Figure \@ref(fig:Missingness) that the missingness is not monotone; subjects may be missing at one time instance and come back later. Since there are too many possible missingness patterns with 23 time instances ($2^{23}$), we do not give an overview of the number of subjects that follow each possible pattern. Instead, figure \@ref(fig:missingnessovertime) shows, for each time instance, the number of subjects that:

- are *present*: when the subject's hearing is measured at time $t$ and $t-1$
- are *missing*: when the subject is missing at time $t$ and $t-1$
- *drop out*: when the subject's hearing is measured at time $t-1$ but not at time$t$
- *return*: when the subject's hearing is measured at time $t$ but not at time $t-1$

Figure \@ref(fig:missingnessovertime) clearly shows that subject rarely are measured two years in a row, most are not measured at $t=1$, and the number of subjects that stay missing gradually increases as time passes.

 
```{r Missingness, include=TRUE, echo = FALSE, message=FALSE, warning=FALSE, fig.cap = "Visual inspection of missingness for different ages at different time instances.", fig.height = 9, fig.width=7}
data_grid %>%
  mutate(TIME_discrete = factor(as.factor(TIME_discrete), ordered = TRUE)) %>%
  group_by(id, TIME_discrete) %>%
  summarize(missing = ifelse(any(!is.na(y)),TRUE, NA),
        age = first(age)) %>%
  ungroup() %>%
  pivot_wider(names_from = TIME_discrete, values_from = missing) %>% 
  arrange(age) %>%
  dplyr::select(3:(3 + max(data_grid$TIME_discrete))) %>%
  vis_miss() + ylab("id sorted by age") +
  theme(plot.margin = margin(0, 1, 0, 0, "cm")) 
```

```{r missingnessovertime, include=TRUE, echo = FALSE, message=FALSE, warning=FALSE, fig.cap = "Number of subjects the are present, return, drop out or are missing at each time instance.", fig.height = 4, fig.width=6}
categorize <- function(x){
  cat <- rep(NA, length(x))
  cat[1] <- ifelse(x[1], "missing", "present")
  if(length(x) > 1){
    l <- lag(x)
    cat[-1] <- ifelse(l[-1],
                      ifelse(x[-1],
                             "missing",
                             "return"),
                      ifelse(x[-1],
                             "drop out",
                             "present"))
  }
  return(cat)
}

data_grid %>%
  group_by(id, TIME_discrete) %>%
  summarize(R = any(R)) %>%
  ungroup() %>%
  group_by(id) %>%
  mutate(missing = factor(as.factor(categorize(R)), ordered = TRUE,
                          levels = c("present", "return", 
                          "drop out", "missing"))) %>%
  ungroup() %>%
  ggplot() +
  geom_bar(aes(x = TIME_discrete, fill = missing)) +
  scale_fill_discrete(name = "") +
  ylab("Number of subjects") + xlab("TIME") +
  theme_bw()
```

Lastly we explore whether the missingness can be explained by the data by fitting a mixed model to a dataset where $R_it$ is equal to one if the hearing threshold is missing and zero otherwise:

\begin{equation}
\left\{
                \begin{array}{ll}
                logit(R_{it}) = \beta_0 + \beta_1 TIME_{it} + \beta_3 side_{it} + \beta_4 age_{it} + \beta_5 R_{it-1} + b_i \\
                b_i \sim N(0,\sigma^2)
                \end{array}
          \right.
(\#eq:missingness)
\end{equation}

The variable *age* was standardized to get convergence in the model. Table \@ref(tab:missingmixedmodel) shows that TIME is significant; as time increases, subjects are more likely to be missing. We can therefore assume missingness at random (MAR). Left ear measurements are also more likely to be missing. A subject is also less likely to be missing at time $t$ if he was missing at time $t-1$. This can be seen especially in the first couple of years in figure \@ref(fig:Missingness): all but 3 subjects are measured at $t=0$, almost no-one is measured at $t=1$ and many are measured again at $t=2$.

```{r missingmixedmodel, include=TRUE, echo = FALSE, message=FALSE, warning=FALSE, eval=TRUE}
library(lme4)
data_grid <- data_grid %>% mutate(
  R_num = 1*(R == TRUE),
  age_scale = scale(age, center = TRUE, scale = TRUE)) %>%
  group_by(id) %>%
  mutate(R_num_lag = dplyr::lag(R_num, n = 1),
         y_last = tail(y[!is.na(y)],1)) %>%
  ungroup()
m1 <- glmer(formula = R_num ~ TIME_discrete + side + age_scale + R_num_lag + (1|id),
        data = data_grid,
        family = binomial(link = "logit"))
s <- summary(m1) 
s$coefficients %>% as.data.frame() %>%
  mutate(var = c('Intercept', "TIME", "sideright", "age", "$R_{t-1}$"),
         result = sprintf("%.2f %s", Estimate, stars.pval(`Pr(>|z|)`))) %>%
  dplyr::select(var, result) %>%
  rbind(c("sigma", round(unname(attr(s$varcor$id, "stddev"))^2,2))) %>%
  kable(booktabs = TRUE,
        caption = "A mixed model to predict missingness.",
        col.names = c('Variable', 'Estimate'),
        row.names = FALSE, 
        escape = FALSE) %>%
  kable_styling()
```


# Methodology

First, a direct likelihood analysis is compared with multiple imputation in the continuous case. 
Next, weighted generalized estimating equations are compared with ‘multiple-imputation generalized estimating equations’. 
Lastly, a sensitivity analysis is performed.

For imputation, the *mice* library is used [@JSSv045i03] and different imputation techniques were tested: Predictive mean matching, Bayesian linear regression, Unconditional mean imputation, and imputation by random forests. 

All analysis was done in R. All scripts are freely available at [this git repository](https://github.com/raiisac/LDA). 

# Results
Q4

## Direct Likelihood Analysis

For the purposes of this section we will analyze the hearing data respective to the continuous response. Two popular ways to analyze data sets with missing data is to use either a direct likelihood method or an analysis through multiple imputation. In a direct likelihood analysis missing values are assumed to be ignorable [ref dlh vs mi]. Drafting a linear mixed effects model within R allows for the direct calculation for each patients' respective likelihood functions. The R-package "nlme" allows for this model to be fit in a way such that the parameter estimates are represntative of their parameters maximum log-likelihood. Aditionally, we will compare models of difering covariance structures: "simple"  and "compound symmetry." Summary statistics for these models can be seen in the following table. 

```{r include=FALSE}
library(nlme)
fit.dlh.cont.simp=lme(y ~ age*TIME_discrete + learning + I(age^2),random = ~1|id,
                 data=data_grid,
                 na.action = na.omit,
                 method = "ML",
                 control=list(msMaxIter = 1000, msMaxEval = 1000))

fit.dlh.cont.compsymm=lme(y ~ age*TIME_discrete + learning + I(age^2),random = ~1|id,
                 data=data_grid,
                 na.action = na.omit,
                 method = "ML",
                 cor = nlme::corCompSymm(),
                 control=list(msMaxIter = 1000, msMaxEval = 1000))
```

```{r include=FALSE}
sum.dlh.simp=summary(fit.dlh.cont.simp)
round(sum.dlh.simp$tTable[,c(1,2,5)],3)

sum.dlh.compsymm=summary(fit.dlh.cont.compsymm)
round(sum.dlh.compsymm$tTable[,c(1,2,5)],3)
```

Parameter estimates from both covariance structures remains constant

## Multiple Imputation

We shall now draft and evaluate models generated by multiple imputation methods. Here artificial data points are generated according to the algorithms: Predictive mean matching, Bayesian linear regression, Unconditional mean imputation, and imputation by random forests. As we are dealing with continuous data, we also consider the two covariance matrix structures: "simple" and "compound symmetry". Being generated from an aggregation of 10 simulations, these simulated data points are then used in conjunction with the real data to draft appropriate models. Their summary statistics are displayed inn the following tables. 


```{r include=FALSE}
load(find_root_file("data/intermediate/raw_imputation.Rdata", 
                    criterion = has_file("LDA.Rproj")))
```

```{r include=FALSE}
# #MI
data_grid_cutdown=data_grid%>%transmute(id,y,TIME_discrete,age,learning)
#
library(mice)
data_grid_mice_norm_long=as.mids(complete(data_grid_mice_norm,action="long",include=TRUE))
#
data_grid_mice_pmm_long=as.mids(complete(data_grid_mice_pmm,action="long",include=TRUE))
#
data_grid_mice_mean_long=as.mids(complete(data_grid_mice_mean,action="long",include=TRUE))
#
data_grid_mice_rf_long=as.mids(complete(data_grid_mice_rf,action="long",include=TRUE))
```

```{r include=FALSE}
# data_imp_mean=data_imp_mean%>%rowwise()%>%mutate(impfullMED=median(c(impfull1,impfull2,impfull3,impfull4,impfull5,impfull6,impfull7,impfull8,impfull9,impfull10)))
# 
# data_imp_norm=data_imp_norm%>%rowwise()%>%mutate(impfullMED=median(impfull1,impfull2,impfull3,impfull4,impfull5,impfull6,impfull7,impfull8,impfull9,impfull10))
# 
# data_imp_pmm=data_imp_pmm%>%rowwise()%>%mutate(impfullMED=median(impfull1,impfull2,impfull3,impfull4,impfull5,impfull6,impfull7,impfull8,impfull9,impfull10))
# 
# data_imp_rf=data_imp_rf%>%rowwise()%>%mutate(impfullMED=median(impfull1,impfull2,impfull3,impfull4,impfull5,impfull6,impfull7,impfull8,impfull9,impfull10))

```

```{r include=FALSE}
lmeControl(maxIter = 1000)

#fit.mi.norm.cont.simp=lme(y ~ age*TIME_discrete + learning + I(age^2),data = data_grid_mice_norm,random = ~1|id)

fit.mi.pmm.cont.simp=with(data_grid_mice_pmm_long,
                          lme(y ~ age*TIME_discrete + learning + I(age^2),random = ~1|id,method = "ML",control=list(msMaxIter = 1000, msMaxEval = 1000)))

fit.mi.mean.cont.simp=with(data_grid_mice_mean_long,
                           lme(y ~ age*TIME_discrete + learning + I(age^2),random = ~1|id,method = "ML",control=list(msMaxIter = 1000, msMaxEval = 1000)))

# fit.mi.mean.cont.simp.v2=with(data_grid_mice_mean_long,
#                               lme(y ~ age*TIME_discrete + learning+ I(age^2),random = ~1|id,method = "ML",control=list(msMaxIter = 1000, msMaxEval = 1000)))

fit.mi.norm.cont.simp=with(data_grid_mice_norm_long,
                           lme(y ~ age*TIME_discrete + learning + I(age^2),random = ~1|id,method = "ML",control=list(msMaxIter = 1000, msMaxEval = 1000)))

fit.mi.rf.cont.simp=with(data_grid_mice_rf_long,
                         lme(y ~ age*TIME_discrete + learning + I(age^2),random = ~1|id,method = "ML",control=list(msMaxIter = 1000, msMaxEval = 1000)))

#fit.mi.rf.cont.simp=lme(y ~ age_scale*TIME_discrete + learning + I(age_scale^2),data = data_grid_mice_rf,random = ~1|id)
```

```{r include=FALSE}
library(broom.mixed)
sum.mi.pmm.cont.simp=round(summary(pool(fit.mi.pmm.cont.simp,rule="reiter2003"))[,c(2:3,6)],3)
rownames(sum.mi.pmm.cont.simp)=summary(pool(fit.mi.pmm.cont.simp,rule="reiter2003"))[,1]

sum.mi.mean.cont.simp=round(summary(pool(fit.mi.mean.cont.simp,rule="reiter2003"))[,c(2:3,6)],3)
rownames(sum.mi.mean.cont.simp)=summary(pool(fit.mi.mean.cont.simp,rule="reiter2003"))[,1]

sum.mi.norm.cont.simp=round(summary(pool(fit.mi.norm.cont.simp,rule="reiter2003"))[,c(2:3,6)],3)
rownames(sum.mi.norm.cont.simp)=summary(pool(fit.mi.norm.cont.simp,rule="reiter2003"))[,1]


sum.mi.rf.cont.simp=round(summary(pool(fit.mi.rf.cont.simp,rule="reiter2003"))[,c(2:3,6)],3)
rownames(sum.mi.rf.cont.simp)=summary(pool(fit.mi.rf.cont.simp,rule="reiter2003"))[,1]

```


```{r include=FALSE}
sum.mi.pmm.cont.simp
sum.mi.mean.cont.simp
sum.mi.norm.cont.simp
sum.mi.rf.cont.simp
```

```{r include=FALSE}
#fit.mi.norm.cont.compsymm=lme(y ~ age_scale*TIME_discrete + learning + I(age_scale^2),data = data_grid_mice_norm,random = ~1|id,cor = nlme::corCompSymm())

fit.mi.pmm.cont.compsymm=with(data_grid_mice_pmm_long,
                          lme(y ~ age*TIME_discrete + learning + I(age^2),random = ~1|id,method = "ML",cor = nlme::corCompSymm(),control=list(msMaxIter = 1000, msMaxEval = 1000)))

fit.mi.mean.cont.compsymm=with(data_grid_mice_mean_long,
                          lme(y ~ age*TIME_discrete + learning + I(age^2),random = ~1|id,method = "ML",cor = nlme::corCompSymm(),control=list(msMaxIter = 1000, msMaxEval = 1000)))

fit.mi.norm.cont.compsymm=with(data_grid_mice_norm_long,
                          lme(y ~ age*TIME_discrete + learning + I(age^2),random = ~1|id,method = "ML",cor = nlme::corCompSymm(),control=list(msMaxIter = 1000, msMaxEval = 1000)))

# fit.mi.rf.cont.compsymm=with(data_grid_mice_rf_long,
#                            lme(y ~ age*TIME_discrete + learning+ I(age^2),random = ~1|id,method = "ML",cor = nlme::corCompSymm(),control=list(msMaxIter = 10000, msMaxEval = 10000)))

#fit.mi.rf.cont.compsymm=lme(y ~ age_scale*TIME_discrete + learning + I(age_scale^2),data = data_grid_mice_rf,random = ~1|id,cor = nlme::corCompSymm())
```

```{r include=FALSE}
sum.mi.pmm.cont.compsymm=round(summary(pool(fit.mi.pmm.cont.compsymm,rule="reiter2003"))[,c(2:3,6)],3)
rownames(sum.mi.pmm.cont.compsymm)=summary(pool(fit.mi.pmm.cont.compsymm,rule="reiter2003"))[,1]

sum.mi.mean.cont.compsymm=round(summary(pool(fit.mi.mean.cont.compsymm,rule="reiter2003"))[,c(2:3,6)],3)
rownames(sum.mi.mean.cont.compsymm)=summary(pool(fit.mi.mean.cont.compsymm,rule="reiter2003"))[,1]

sum.mi.norm.cont.compsymm=round(summary(pool(fit.mi.norm.cont.compsymm,rule="reiter2003"))[,c(2:3,6)],3)
rownames(sum.mi.norm.cont.compsymm)=summary(pool(fit.mi.norm.cont.compsymm,rule="reiter2003"))[,1]
```

```{r include=FALSE}
#pmm
sum.mi.pmm.cont.compsymm
#uncon. mean
sum.mi.mean.cont.compsymm
#bayes lr
sum.mi.norm.cont.compsymm
```

```{r eval=FALSE, include=FALSE}
sum.mi.pmm.cont.compsymm==sum.mi.pmm.cont.simp
sum.mi.mean.cont.compsymm==sum.mi.mean.cont.simp
sum.mi.norm.cont.compsymm==sum.mi.norm.cont.simp
```



Respective to the different covariance structures, parameter estimates are largely the same between model pairs of opposing covariance patterns. For this reason, the following analysis will only consider the models fit according to a simple covariance structure. Comparing model parameter estimates shows that the models do differ in regards to how the fixed effects regression coefficients are computed; with no two models agreeing perfectly on every parameter estimate in regards to sign or magnitude. As these are mixed models, interpretting the fixed effects without consideration of the random effects is innapropraite. Additionally, as data sets are non-standard amongst each of these models, many traditional metrics such as AIC and BIC would also be   innapropriate. Instead we shall focus on predicive metrics as these should inform us of each of the models potential practical implications. 

## Direct Likelihood vs. Multiple Imputation

To cross evaluate these models and the model drafted from a direct likelihood approach, we shall consider an analysis of the emperically observed within-group standardized residuals. For the models drafted through multiple imputation, to minimize potential bias inflation from the impuation processes, we shall consider a worst case scenario; where these residuals are assumed to rest within the largest possible observed interval between the 10 models.

```{r}
res_int_pmm=matrix(rep(0,20),ncol=2)
for(i in 1:10){
  res_int_pmm[i,1]=c(summary(fit.mi.pmm.cont.simp$analyses[[i]])$residuals[1])
  res_int_pmm[i,2]=c(summary(fit.mi.pmm.cont.simp$analyses[[i]])$residuals[5])
  #res_int[i,3]=res_int[i,2]-res_int[i,1]
}
#max(res_int_pmm[,2])-min(res_int_pmm[,1])

res_int_mean=matrix(rep(0,20),ncol=2)
for(i in 1:10){
  res_int_mean[i,1]=c(summary(fit.mi.mean.cont.simp$analyses[[i]])$residuals[1])
  res_int_mean[i,2]=c(summary(fit.mi.mean.cont.simp$analyses[[i]])$residuals[5])
  #res_int[i,3]=res_int[i,2]-res_int[i,1]
}
#max(res_int_mean[,2])-min(res_int_mean[,1])

res_int_norm=matrix(rep(0,20),ncol=2)
for(i in 1:10){
  res_int_norm[i,1]=c(summary(fit.mi.norm.cont.simp$analyses[[i]])$residuals[1])
  res_int_norm[i,2]=c(summary(fit.mi.norm.cont.simp$analyses[[i]])$residuals[5])
  #res_int[i,3]=res_int[i,2]-res_int[i,1]
}
#max(res_int_norm[,2])-min(res_int_norm[,1])

res_int_rf=matrix(rep(0,20),ncol=2)
for(i in 1:10){
  res_int_rf[i,1]=c(summary(fit.mi.rf.cont.simp$analyses[[i]])$residuals[1])
  res_int_rf[i,2]=c(summary(fit.mi.rf.cont.simp$analyses[[i]])$residuals[5])
  #res_int[i,3]=res_int[i,2]-res_int[i,1]
}
#max(res_int_rf[,2])-min(res_int_rf[,1])

res_int_full=matrix(rep(0,15),ncol=3)
res_int_full[1,1:2]=c(min(res_int_pmm[,1]),max(res_int_pmm[,2]))
res_int_full[2,1:2]=c(min(res_int_mean[,1]),max(res_int_mean[,2]))
res_int_full[3,1:2]=c(min(res_int_norm[,1]),max(res_int_norm[,2]))
res_int_full[4,1:2]=c(min(res_int_rf[,1]),max(res_int_rf[,2]))
res_int_full[5,1:2]=c(sum.dlh.simp$residuals[1],sum.dlh.simp$residuals[5])
res_int_full[,3]=res_int_full[,2]-res_int_full[,1]

row.names(res_int_full)=c("PMM","Mean","Norm","RF","DL")
colnames(res_int_full)=c("Min SR","Max SR","SR Int. Length")

res_int_full=round(res_int_full,3)
res_int_full
```

From this metric we observe that the direct likelihood (DL) method results in the smallest interval of emperically observed within-group standardized residuals, with unconditional mean imputation (Mean) potentially resulting in largest degree of error. As will be discusssed in further sections, the impact of predictive bias will be further explored to generate a much more thorough understanding of how well these models may preform.


## Weighted generalized estimating equations versus ‘multiple-imputation generalized estimating equations’
Using frequentist methods,
Q5

## Sensitivity analysis

Q6

# Bibliography

