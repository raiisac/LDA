---
documentclass: article
fontsize: 12pt
date: "`r Sys.Date()`"
output: 
  bookdown::pdf_document2: 
    toc: false
    latex_engine: xelatex
    fig_caption: yes
    includes:
      in_header: preamble.sty
      before_body: titlepage.sty
bibliography: references.bib  
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
library(broom.mixed)
library(tidyverse)
library(haven) # to read SAS files
library(kableExtra)
library(qwraps2)
library(rprojroot)
library(patchwork)
library(psych)
library(geepack)
library(gtools)
library(ordinal)
library(visdat)#visualize missingness
library(mice)
library(nlme)
library(lme4)
library(latex2exp)
knitr::opts_chunk$set(echo = TRUE)
```

```{r load, include=FALSE, message=FALSE, warning=FALSE}
trichotomization <- c(-100, 6, 25, 120)
data <- read_sas(find_root_file("data/hearing500lr.sas7bdat",
                                criterion = has_file("LDA.Rproj"))) %>%
  mutate(side = as.factor(side),
         side_integer = as.integer(side),
         TIME_discrete = round(TIME),
         id = as.factor(id),
         id_integer = as.integer(id),
         age_measurement = age + TIME,
         age_scale = unname(scale(age, center = TRUE, scale = TRUE)),
         age_discrete = cut(age,
                            breaks = c(0,30,50,70,100),
                            labels = c("<30", "30-50", "50-70",">70")),
         y_discrete = factor(as.factor(cut(y,
                          breaks = trichotomization,
                          labels = c("Excellent", "Normal", "Hearing loss"))),
                          levels = c("Excellent", "Normal", "Hearing loss"),
                          ordered = TRUE),
         y_integer = as.integer(y_discrete),
         learning = 1*(TIME == 0)) %>%
  arrange(id)
subject_characteristics <- data %>%
  group_by(id) %>%
  summarize(age = first(age),
            age_scale = first(age_scale),
            age_discrete = first(age_discrete),
            id_integer = first(id_integer)) %>%
  ungroup()
  
data_grid <- expand.grid(id = unique(data$id),
                         TIME_discrete = 0:max(data$TIME_discrete),
                         side = unique(data$side)) %>%
  left_join(data %>% dplyr::select(-age, -age_scale, -age_discrete, 
                                   -id_integer)) %>%
  mutate(R = is.na(y), # R denotes missingness
         learning = (TIME_discrete == 0)) %>%
  left_join(subject_characteristics, by = c("id" = "id")) #add the subject characteristics back in)
```

# Introduction

This report assesses the evolution of hearing thresholds over time for a sample of `r nlevels(data$id)` healthy male volunteers. The data originates from the famous Baltimore Longitudinal Study of Aging (BLSA). Previous research showed a change in hearing threshold for all age groups but especially the older population [@doi:10.1121/1.399731]. In this report, we will especially take care of missingness in the data.

First, the *TIME* variable is rounded to the nearest integer value. As such, we aim to balance the dataset with equally-spaced time instances when hearing thresholds are measured. 

Hearing thresholds will be explored as a continuous variable.

## Missingness exploration
```{r Missingnessprep, include=FALSE, message=FALSE, warning=FALSE}
data_by_id_time <- data_grid %>% 
  group_by(id, TIME_discrete) %>%
  summarize(n = sum(!is.na(y_discrete))) %>%
  ungroup()
```

After discretizing the *TIME* variable, we consider a subject to be missing at a certain time instance if there is no measurement for that subject at that time. It should be noted that, if the subject is not missing (`r round((1-sum(data_by_id_time$n==0)/nrow(data_by_id_time))*100,2)`% of TIME-subject instances), we usually (`r round((sum(data_by_id_time$n==2)/nrow(data_by_id_time))*100,2)`% of TIME-subject instances) have two measurements (one for each ear) at each time instance. In fact, the average number of measurements per subject at each time instance is `r round(mean(data_by_id_time$n),2)`, and maximum `r round(max(data_by_id_time$n),2)`. 

Figure \@ref(fig:Missingness) was created using the *visdat* package. It shows all subjects, ordered from youngest (in the top) to oldest (in the bottom) and whether or not their data is missing at a certain time instance (on the x-axis). The percentages on top shows the percentage of missingness at each time instance. It is clear from Figure \@ref(fig:Missingness) that the missingness is not monotone; subjects may be missing at one time instance and come back later. Since there are too many possible missingness patterns with 23 time instances ($2^{23}$), we do not give an overview of the number of subjects that follow each possible pattern. Instead, figure \@ref(fig:missingnessovertime) shows, for each time instance, the number of subjects that:

- are *present*: when the subject's hearing is measured at time $t$ and $t-1$
- are *missing*: when the subject is missing at time $t$ and $t-1$
- *drop out*: when the subject's hearing is measured at time $t-1$ but not at time$t$
- *return*: when the subject's hearing is measured at time $t$ but not at time $t-1$

Figure \@ref(fig:missingnessovertime) clearly shows that subject rarely are measured two years in a row, most are not measured at $t=1$, and the number of subjects that stay missing gradually increases as time passes.

 
```{r Missingness, include=TRUE, echo = FALSE, message=FALSE, warning=FALSE, fig.cap = "Visual inspection of missingness for different ages at different time instances.", fig.height = 9, fig.width=7}
data_grid %>%
  mutate(TIME_discrete = factor(as.factor(TIME_discrete), ordered = TRUE)) %>%
  group_by(id, TIME_discrete) %>%
  summarize(missing = ifelse(any(!is.na(y)),TRUE, NA),
        age = first(age)) %>%
  ungroup() %>%
  pivot_wider(names_from = TIME_discrete, values_from = missing) %>% 
  arrange(age) %>%
  dplyr::select(3:(3 + max(data_grid$TIME_discrete))) %>%
  vis_miss() + ylab("id sorted by age") +
  theme(plot.margin = margin(0, 1, 0, 0, "cm")) 
```

```{r missingnessovertime, include=TRUE, echo = FALSE, message=FALSE, warning=FALSE, fig.cap = "Number of subjects the are present, return, drop out or are missing at each time instance.", fig.height = 4, fig.width=6}
categorize <- function(x){
  cat <- rep(NA, length(x))
  cat[1] <- ifelse(x[1], "missing", "present")
  if(length(x) > 1){
    l <- lag(x)
    cat[-1] <- ifelse(l[-1],
                      ifelse(x[-1],
                             "missing",
                             "return"),
                      ifelse(x[-1],
                             "drop out",
                             "present"))
  }
  return(cat)
}

data_grid %>%
  group_by(id, TIME_discrete) %>%
  summarize(R = any(R)) %>%
  ungroup() %>%
  group_by(id) %>%
  mutate(missing = factor(as.factor(categorize(R)), ordered = TRUE,
                          levels = c("present", "return", 
                          "drop out", "missing"))) %>%
  ungroup() %>%
  ggplot() +
  geom_bar(aes(x = TIME_discrete, fill = missing)) +
  scale_fill_discrete(name = "") +
  ylab("Number of subjects") + xlab("TIME") +
  theme_bw()
```

Lastly we explore whether the missingness can be explained by the data by fitting a mixed model to a dataset where $R_it$ is equal to one if the hearing threshold is missing and zero otherwise:

\begin{equation}
\left\{
                \begin{array}{ll}
                logit(R_{it}) = \beta_0 + \beta_1 TIME_{it} + \beta_3 side_{it} + \beta_4 age_{it} + \beta_5 R_{it-1} + b_i \\
                b_i \sim N(0,\sigma^2)
                \end{array}
          \right.
(\#eq:missingness)
\end{equation}

The variable *age* was standardized to get convergence in the model. Table \@ref(tab:missingmixedmodel) shows that TIME is significant; as time increases, subjects are more likely to be missing. We can therefore assume missingness at random (MAR). Left ear measurements are also more likely to be missing. A subject is also less likely to be missing at time $t$ if he was missing at time $t-1$. This can be seen especially in the first couple of years in figure \@ref(fig:Missingness): all but 3 subjects are measured at $t=0$, almost no-one is measured at $t=1$ and many are measured again at $t=2$.

```{r missingmixedmodel, include=TRUE, echo = FALSE, message=FALSE, warning=FALSE, eval=TRUE}
data_grid <- data_grid %>% mutate(
  R_num = 1*(R == TRUE),
  age_scale = scale(age, center = TRUE, scale = TRUE)) %>%
  group_by(id) %>%
  mutate(R_num_lag = dplyr::lag(R_num, n = 1),
         y_last = tail(y[!is.na(y)],1)) %>%
  ungroup()
m1 <- glmer(formula = R_num ~ TIME_discrete + side + age_scale + R_num_lag + (1|id),
        data = data_grid,
        family = binomial(link = "logit"))
s <- summary(m1) 
s$coefficients %>% as.data.frame() %>%
  mutate(var = c('Intercept', "TIME", "sideright", "age", "$R_{t-1}$"),
         result = sprintf("%.2f %s", Estimate, stars.pval(`Pr(>|z|)`))) %>%
  dplyr::select(var, result) %>%
  rbind(c("sigma", round(unname(attr(s$varcor$id, "stddev"))^2,2))) %>%
  kable(booktabs = TRUE,
        caption = "A mixed model to predict missingness.",
        col.names = c('Variable', 'Estimate'),
        row.names = FALSE, 
        escape = FALSE) %>%
  kable_styling()
```


# Methodology

First, a direct likelihood analysis is compared with multiple imputation in the continuous case. 
Next, weighted generalized estimating equations are compared with ‘multiple-imputation generalized estimating equations’. 
Lastly, a sensitivity analysis is performed.

For imputation, the *mice* library is used [@JSSv045i03] and different imputation techniques were tested: Predictive mean matching, Bayesian linear regression, Unconditional mean imputation, and imputation by random forests. 

All analysis was done in R. All scripts are freely available at [this git repository](https://github.com/raiisac/LDA). 

# Results

## Direct Likelihood Analysis

For the purposes of this section we will analyze the hearing data respective to the continuous response. Two popular ways to analyze data sets with missing data is to use either a direct likelihood method or an analysis through multiple imputation. In a direct likelihood analysis, missing values are assumed to be ignorable [@BeunckensCaroline2005Dlav]. Drafting a linear mixed effects model within R allows for the direct calculation for each patients' respective likelihood functions. The R-package *nlme* allows for this model to be fit in a way such that the parameter estimates are representative of their parameters' maximum log-likelihood. Additionally, we will compare models of differing covariance structures: "simple"  and "compound symmetry." Summary statistics for these models can be seen in Table \@ref(tab:DLMISimple). 

```{r include=FALSE}
fit.dlh.cont.simp = lme(y ~ age*TIME_discrete + learning + I(age^2),
                        random = ~1|id,
                        data = data_grid,
                        na.action = na.omit,
                        method = "ML",
                        control = list(msMaxIter = 1000, msMaxEval = 1000))

fit.dlh.cont.compsymm = lme(y ~ age*TIME_discrete + learning + I(age^2),
                            random = ~1|id,
                            data = data_grid,
                            na.action = na.omit,
                            method = "ML",
                            cor = nlme::corCompSymm(),
                            control = list(msMaxIter = 1000, msMaxEval = 1000))
```

```{r directlikelihood, include=FALSE}
sum.dlh.simp = summary(fit.dlh.cont.simp)
simple <- round(sum.dlh.simp$tTable[,c(1,2,5)],3) %>%
  as.data.frame() %>%
  mutate(txt = sprintf("%.3f (%.3f)%s", Value,  Std.Error, stars.pval(`p-value`)),
         var = rownames(sum.dlh.simp$tTable))%>%
  dplyr::select(var, txt)

sum.dlh.compsymm=summary(fit.dlh.cont.compsymm)
cs <- round(sum.dlh.compsymm$tTable[,c(1,2,5)],3) %>%
  as.data.frame() %>%
  mutate(txt2 = sprintf("%.3f (%.3f)%s", Value,  Std.Error, stars.pval(`p-value`)))%>%
  dplyr::select(txt2)

simple %>% cbind(cs) %>%
  kable(booktabs = TRUE,
        col.names = c("Variable", "Estimate (std.error)", "Estimate (std.error)"),
        caption = "Direct likelihood results.",
        row.names = FALSE) %>%
  add_header_above(c("", "Simple cov. struct.", "Compound Symmetry cov. struct."))
```

Parameter estimates from both covariance structures remain stable.

### Multiple Imputation

We shall now draft and evaluate models generated by multiple imputation methods. Here, artificial data points are generated according to the algorithms: Predictive mean matching, Bayesian linear regression, Unconditional mean imputation, and imputation by random forests. As we are dealing with continuous data, we also consider two covariance matrix structures: "simple" and "compound symmetry". Being generated from an aggregation of 10 simulations, these simulated data points are then used in conjunction with the real data to draft appropriate models. Their summary statistics are displayed in Table \@ref(tab:DLMISimple) and \@ref(tab:DLMICompsymm). 


```{r include=FALSE}
load(find_root_file("data/intermediate/raw_imputation.Rdata", 
                    criterion = has_file("LDA.Rproj")))
```

```{r include=FALSE}
# #MI
data_grid_cutdown=data_grid%>%transmute(id,y,TIME_discrete,age,learning)
#
data_grid_mice_norm_long=as.mids(complete(data_grid_mice_norm,action="long",include=TRUE))
#
data_grid_mice_pmm_long=as.mids(complete(data_grid_mice_pmm,action="long",include=TRUE))
#
data_grid_mice_mean_long=as.mids(complete(data_grid_mice_mean,action="long",include=TRUE))
#
data_grid_mice_rf_long=as.mids(complete(data_grid_mice_rf,action="long",include=TRUE))
```

```{r include=FALSE, eval=FALSE}
lmeControl(maxIter = 1000,
           opt = "optim")

#fit.mi.norm.cont.simp=lme(y ~ age*TIME_discrete + learning + I(age^2),data = data_grid_mice_norm,random = ~1|id)

fit.mi.pmm.cont.simp = with(data_grid_mice_pmm_long,
                            lme(y ~ age*TIME_discrete + learning + I(age^2),
                                random = ~1|id,method = "ML",
                                control = list(msMaxIter = 1000, 
                                               msMaxEval = 1000)))

fit.mi.mean.cont.simp = with(data_grid_mice_mean_long,
                           lme(y ~ age*TIME_discrete + learning + I(age^2), 
                               random = ~1|id, method = "ML",
                               control=list(msMaxIter = 1000, 
                                            msMaxEval = 1000)))

# fit.mi.mean.cont.simp.v2=with(data_grid_mice_mean_long,
#                               lme(y ~ age*TIME_discrete + learning+ I(age^2),random = ~1|id,method = "ML",control=list(msMaxIter = 1000, msMaxEval = 1000)))

fit.mi.norm.cont.simp = with(data_grid_mice_norm_long,
                           lme(y ~ age*TIME_discrete + learning + I(age^2),
                               random = ~1|id,
                               method = "ML",
                               control = list(msMaxIter = 1000,
                                              msMaxEval = 1000)))

fit.mi.rf.cont.simp = with(data_grid_mice_rf_long,
                         lme(y ~ age*TIME_discrete + learning + I(age^2),
                             random = ~1|id,
                             method = "ML",
                             control = list(msMaxIter = 1000, 
                                            msMaxEval = 1000)))

#fit.mi.rf.cont.simp=lme(y ~ age_scale*TIME_discrete + learning + I(age_scale^2),data = data_grid_mice_rf,random = ~1|id)
```

```{r DLMISimple, include=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
load("Ken Code/directlikelihoodresults.Rdata")
#sum.mi.mean.cont.simp = round(summary(pool(fit.mi.mean.cont.simp,rule = "reiter2003"))[,c(2:3,6)],3)
#rownames(sum.mi.mean.cont.simp)=summary(pool(fit.mi.mean.cont.simp,rule="reiter2003"))[,1]
sum.mi.mean.cont.simp <- sum.mi.mean.cont.simp%>%
  as.data.frame() %>%
  mutate(txtmean = sprintf("%.3f (%.3f)%s", estimate,  std.error, stars.pval(p.value)),
         var = str_remove(str_remove(rownames(sum.mi.mean.cont.simp), 
                                     "_discrete"), "TRUE")) %>%
  dplyr::select(var, txtmean)

#sum.mi.rf.cont.simp=round(summary(pool(fit.mi.rf.cont.simp,rule="reiter2003"))[,c(2:3,6)],3)
#rownames(sum.mi.rf.cont.simp)=summary(pool(fit.mi.rf.cont.simp,rule="reiter2003"))[,1]
sum.mi.rf.cont.simp <- sum.mi.rf.cont.simp%>%
  as.data.frame() %>%
  mutate(txtrf = sprintf("%.3f (%.3f)%s", estimate,  std.error, stars.pval(p.value))) %>%
  dplyr::select(txtrf)
#sum.mi.norm.cont.simp=round(summary(pool(fit.mi.norm.cont.simp,rule="reiter2003"))[,c(2:3,6)],3)
#rownames(sum.mi.norm.cont.simp)=summary(pool(fit.mi.norm.cont.simp,rule="reiter2003"))[,1]
sum.mi.norm.cont.simp <- sum.mi.norm.cont.simp%>%
  as.data.frame() %>%
  mutate(txtnorm = sprintf("%.3f (%.3f)%s", estimate,  std.error, stars.pval(p.value))) %>%
  dplyr::select(txtnorm)

#sum.mi.pmm.cont.simp=round(summary(pool(fit.mi.pmm.cont.simp,rule="reiter2003"))[,c(2:3,6)],3)
#rownames(sum.mi.pmm.cont.simp)=summary(pool(fit.mi.pmm.cont.simp,rule="reiter2003"))[,1]
sum.mi.pmm.cont.simp <- sum.mi.pmm.cont.simp%>%
  as.data.frame() %>%
  mutate(txtpmm = sprintf("%.3f (%.3f)%s", estimate,  std.error, stars.pval(p.value))) %>%
  dplyr::select(txtpmm)

sum.mi.mean.cont.simp %>%
  cbind(sum.mi.rf.cont.simp) %>%
  cbind(sum.mi.norm.cont.simp) %>%
  cbind(sum.mi.pmm.cont.simp) %>%
  kable(booktabs = TRUE,
        col.names = c("Variable", "Estimate (std.error)", "Estimate (std.error)", "Estimate (std.error)", "Estimate (std.error)"),
        caption = "Direct likelihood with MI, simple cov. struct.",
        row.names = FALSE) %>%
  add_header_above(c("", "Mean imputation", "Random \nforest", 
                     "Bayesian linear \nregression", "Predictive \nmean matching")) 

```



```{r include=FALSE, eval = FALSE}
#fit.mi.norm.cont.compsymm=lme(y ~ age_scale*TIME_discrete + learning + I(age_scale^2),data = data_grid_mice_norm,random = ~1|id,cor = nlme::corCompSymm())

fit.mi.pmm.cont.compsymm = with(data_grid_mice_pmm_long,
                          lme(y ~ age*TIME_discrete + learning + I(age^2),
                              random = ~1|id,
                              method = "ML",
                              cor = nlme::corCompSymm(),
                              control = list(msMaxIter = 1000, 
                                           msMaxEval = 1000)))

fit.mi.mean.cont.compsymm = with(data_grid_mice_mean_long,
                          lme(y ~ age*TIME_discrete + learning + I(age^2),
                              random = ~1|id,
                              method = "ML",
                              cor = nlme::corCompSymm(),
                              control = list(msMaxIter = 1000, 
                                           msMaxEval = 1000)))

fit.mi.norm.cont.compsymm = with(data_grid_mice_norm_long,
                          lme(y ~ age*TIME_discrete + learning + I(age^2),
                              random = ~1|id,method = "ML",
                              cor = nlme::corCompSymm(),
                              control = list(msMaxIter = 1000, msMaxEval = 1000)))
#rf doesn't converge
fit.mi.rf.cont.compsymm = with(data_grid_mice_rf_long,
                            lme(y ~ age*TIME_discrete + learning+ I(age^2),
                                random = ~1|id,method = "ML",
                                cor = nlme::corCompSymm(),
                                control = list(msMaxIter = 10000, msMaxEval = 10000)))

#fit.mi.rf.cont.compsymm=lme(y ~ age_scale*TIME_discrete + learning + I(age_scale^2),data = data_grid_mice_rf,random = ~1|id,cor = nlme::corCompSymm())
```

```{r DLMICompsymm, include = TRUE,  echo = FALSE}
#sum.mi.pmm.cont.compsymm=round(summary(pool(fit.mi.pmm.cont.compsymm,rule="reiter2003"))[,c(2:3,6)],3)
#rownames(sum.mi.pmm.cont.compsymm)=summary(pool(fit.mi.pmm.cont.compsymm,rule="reiter2003"))[,1]
sum.mi.pmm.cont.compsymm <- sum.mi.pmm.cont.compsymm %>%
  as.data.frame() %>%
  mutate(txtpmm = sprintf("%.3f (%.3f)%s", estimate,  std.error, stars.pval(p.value))) %>%
  dplyr::select(txtpmm)

#sum.mi.mean.cont.compsymm=round(summary(pool(fit.mi.mean.cont.compsymm,rule="reiter2003"))[,c(2:3,6)],3)
#rownames(sum.mi.mean.cont.compsymm)=summary(pool(fit.mi.mean.cont.compsymm,rule="reiter2003"))[,1]
sum.mi.mean.cont.compsymm <- sum.mi.mean.cont.compsymm%>%
  as.data.frame() %>%
  mutate(txtmean = sprintf("%.3f (%.3f)%s", estimate,  std.error, stars.pval(p.value)),
         var = str_remove(str_remove(rownames(sum.mi.mean.cont.compsymm), "_discrete"), "TRUE")) %>%
  dplyr::select(var, txtmean)

#sum.mi.norm.cont.compsymm=round(summary(pool(fit.mi.norm.cont.compsymm,rule="reiter2003"))[,c(2:3,6)],3)
#rownames(sum.mi.norm.cont.compsymm)=summary(pool(fit.mi.norm.cont.compsymm,rule="reiter2003"))[,1]
sum.mi.norm.cont.compsymm <- sum.mi.norm.cont.compsymm%>%
  as.data.frame() %>%
  mutate(txtnorm = sprintf("%.3f (%.3f)%s", estimate,  std.error, stars.pval(p.value))) %>%
  dplyr::select(txtnorm)

# sum.mi.rf.cont.compsymm=round(summary(pool(fit.mi.rf.cont.compsymm,rule="reiter2003"))[,c(2:3,6)],3)
# rownames(sum.mi.rf.cont.compsymm)=summary(pool(fit.mi.rf.cont.compsymm,rule="reiter2003"))[,1]
# sum.mi.rf.cont.compsymm <- sum.mi.rf.cont.compsymm%>%
#   as.data.frame() %>%
#   mutate(txtrf = sprintf("%.3f (%.3f)%s", estimate,  std.error, stars.pval(p.value))) %>%
#   dplyr::select(txtrf)

sum.mi.mean.cont.compsymm %>%
  #cbind(sum.mi.rf.cont.compsymm) %>%
  cbind(sum.mi.norm.cont.compsymm) %>%
  cbind(sum.mi.pmm.cont.compsymm) %>%
  kable(booktabs = TRUE,
        col.names = c("Variable", "Estimate (std.error)", "Estimate (std.error)", "Estimate (std.error)"),
        caption = "Direct likelihood with MI, compound symmetry cov. struct.",
        row.names = FALSE) %>%
  add_header_above(c("", "Mean imputation", 
                     "Bayesian linear \nregression", "Predictive \nmean matching"))

```

Respective to the different covariance structures, parameter estimates are largely the same between model pairs of opposing covariance patterns. For this reason, the following analysis will only consider the models fit according to a simple covariance structure. Comparing model parameter estimates shows that the models do differ in regards to how the fixed effects regression coefficients are computed; with no two models agreeing perfectly on every parameter estimate in regards to sign or magnitude. As these are mixed models, interpreting the fixed effects without consideration of the random effects is innapropraite. Additionally, as data sets are non-standard amongst each of these models, many traditional metrics such as AIC and BIC would also be   inapropriate. Instead we shall focus on predicive metrics as these should inform us of each of the models potential practical implications. 

### Direct Likelihood vs. Multiple Imputation

To cross evaluate these models and the model drafted from a direct likelihood approach, we shall consider an analysis of the empirically observed within-group standardized residuals. For the models drafted through multiple imputation, to minimize potential bias inflation from the imputation processes, we shall consider a worst case scenario; where these residuals are assumed to rest within the largest possible observed interval between the 10 models (Table \@ref(tab:DLvsMI)).

```{r eval=FALSE, include = FALSE}
res_int_pmm=matrix(rep(0,20),ncol=2)
for(i in 1:10){
  res_int_pmm[i,1]=c(summary(fit.mi.pmm.cont.simp$analyses[[i]])$residuals[1])
  res_int_pmm[i,2]=c(summary(fit.mi.pmm.cont.simp$analyses[[i]])$residuals[5])
  #res_int[i,3]=res_int[i,2]-res_int[i,1]
}
#max(res_int_pmm[,2])-min(res_int_pmm[,1])

res_int_mean=matrix(rep(0,20),ncol=2)
for(i in 1:10){
  res_int_mean[i,1]=c(summary(fit.mi.mean.cont.simp$analyses[[i]])$residuals[1])
  res_int_mean[i,2]=c(summary(fit.mi.mean.cont.simp$analyses[[i]])$residuals[5])
  #res_int[i,3]=res_int[i,2]-res_int[i,1]
}
#max(res_int_mean[,2])-min(res_int_mean[,1])

res_int_norm=matrix(rep(0,20),ncol=2)
for(i in 1:10){
  res_int_norm[i,1]=c(summary(fit.mi.norm.cont.simp$analyses[[i]])$residuals[1])
  res_int_norm[i,2]=c(summary(fit.mi.norm.cont.simp$analyses[[i]])$residuals[5])
  #res_int[i,3]=res_int[i,2]-res_int[i,1]
}
#max(res_int_norm[,2])-min(res_int_norm[,1])

res_int_rf=matrix(rep(0,20),ncol=2)
for(i in 1:10){
  res_int_rf[i,1]=c(summary(fit.mi.rf.cont.simp$analyses[[i]])$residuals[1])
  res_int_rf[i,2]=c(summary(fit.mi.rf.cont.simp$analyses[[i]])$residuals[5])
  #res_int[i,3]=res_int[i,2]-res_int[i,1]
}
#max(res_int_rf[,2])-min(res_int_rf[,1])

res_int_full=matrix(rep(0,15),ncol=3)
res_int_full[1,1:2]=c(min(res_int_pmm[,1]),max(res_int_pmm[,2]))
res_int_full[2,1:2]=c(min(res_int_mean[,1]),max(res_int_mean[,2]))
res_int_full[3,1:2]=c(min(res_int_norm[,1]),max(res_int_norm[,2]))
res_int_full[4,1:2]=c(min(res_int_rf[,1]),max(res_int_rf[,2]))
res_int_full[5,1:2]=c(sum.dlh.simp$residuals[1],sum.dlh.simp$residuals[5])
res_int_full[,3]=res_int_full[,2]-res_int_full[,1]

row.names(res_int_full)=c("PMM","Mean","Norm","RF","DL")
colnames(res_int_full)=c("Min SR","Max SR","SR Int. Length")

res_int_full=round(res_int_full,3)
res_int_full
```

```{r DLvsMI, include= TRUE, echo=FALSE}
res_int_full %>% as.data.frame() %>%
  mutate(Method = c('Predictive mean matching', 'Bayesian linear regression', 'Unconditional mean imputation', 'Random forests', 'Direct likelihood')) %>%
  dplyr::select(Method, `Min SR`, `Max SR`, `SR Int. Length`) %>%
  kable(booktabs = TRUE,
        row.names = FALSE,
        caption = "A comparison of direct likelihood and MI methods")
```

From this metric, we observe that the direct likelihood (DL) method results in the smallest interval of empirically observed within-group standardized residuals, with unconditional mean imputation (Mean) potentially resulting in largest degree of error. As will be discussed in further sections, the impact of predictive bias will be further explored to generate a much more thorough understanding of how well these models may preform.


## Weighted generalized estimating equations versus ‘multiple-imputation generalized estimating equations’
In this section we will first explain our specification of the weighted generalized estimating equations, then we will explain the methodology behind the 'multiple-imputation generalized estimating equations' and finally we will compare the models.

### Weighted generalized estimating equations

First we specify the weights by using the inverse dropout probability methodology described in the lecture notes. The logistic regression model to predict missingness($R$) is the following; 
\begin{equation}
\left\{
                \begin{array}{ll}
                logit(R) = \beta_0 + \beta_k TIME_k + \beta_3 side + \beta_4 age  + b \\
                b \sim N(0,\sigma^2)\\
                k \in {0, 1, \dots, 22}
                \end{array}
          \right.
\end{equation}

It should be noted that we created a dummy variable for each period in the TIME variable with the first being $TIME=0$ and the last $TIME=22$. There are certain periods (e.g. $TIME=1,3$) with very few observations. We specified the dummy variables with the hope of capturing any such effects. The model above had the best performance in terms of AIC. \newline After specifying the weights, we proceed with model selection of the Weighted GEE. For this purpose, we use QIC and a greedy methodology. Starting from a fully specified model we remove redundant variables from the model until we cannot simplify the model any more without sacrificing performance. The final model we chose contains the variables $$age + TIME + age^2+ age*TIME$$ As a final step we explore the correlation structure of the model using the QICu. The best performing is an independent correlation structure. The model coefficients as well as its error can be seen in the table bellow. We note that the variable $age$ is not significant but we nevertheless include it as $age^2$ is significant. Further we note that this model is almost the same as the best performing model for the normal un-weighted GEE, the only difference being that the later also includes the learning effect dummy variable for the first observation.

```{r include=FALSE}
data_grid <- data_grid %>% mutate("R_int"=1-as.numeric(data_grid$R))
data_grid <- data_grid[order(data_grid$id, data_grid$TIME_discrete),]
glmweight <-glm(R_int ~ as.factor(TIME_discrete)  + side + age_scale, data = data_grid, family = "binomial")
summary(glmweight)

wgee3 <- geeglm(y ~ age+TIME_discrete+age:TIME_discrete + I(age^2), 
                data=data_grid, 
                id=id,
                family = "gaussian",
                corstr="independence",
                weights = glmweight[["fitted.values"]])


d1<-as.data.frame(summary(wgee3)[["coefficients"]][1:2])
d1<-d1 %>% 
  mutate(across(where(is.numeric), round, digits=3))

d<-d1


d1[6,]<-c("RMSE",round(mean(sqrt(resid(wgee3)^2)),3))
#d1[6,]<-c("RMSE",round(mean(na.omit(sqrt(resid(wgee3)[!is.na(data_grid$y)]^2))),3))

row.names(d1)[6]<-" "

load("data/imputated_data.RData")
```

### Multiple imputation GEE


In this section, we will discuss the multiple imputation GEE approach. We employ the same 4 different imputation methodsas in section 3.1.1.: Predictive mean matching, Bayesian linear regression, Unconditional mean imputation and imputation by Random Forest. For each, we generate 10 Fully conditional and 10 Monotone multiple imputations leading to a total of 80 imputed data sets (40 FCS and 40 Monotone). The main idea of this method is to replace missing values with $M$ plausible values drawn from the conditional distribution of the missing values given the observed data. This conditional distribution represents how uncertain we are about the right value to impute. We evaluate 3 Multiple imputation models:firstly, a model based on all imputed data sets, both monotone and FCS, secondly a model based only on the FCS imputation, and thirdly a model based only on the monotone imputation. \newline

From each imputed data set, we evaluate $\widehat{\beta}^k$ using the same model and correlation structure as above. Here, we note a few important points. First, if we perform a model selection on the imputed data sets, we notice that there are non trivial differences between the best performing model and its correlation structure for the different imputed data sets. We hypothesise that these differences arise from the large number of values we need to impute. For most subjects, we have more imputed data than actual observations. Further, if we do not impute values after the last true measurement of each subject, which greatly reduces the number of imputed values, both models and correlation structure stabilize into models similar to the best performing un-weighted GEE. Secondly, if we impute less data points the performance of the MI GEE on the true data tends to be better. Nevertheless we will conduct the analysis with the full missing data imputation from $TIME=0$ to $TIME=22$. \newline After having evaluated all models based on the imputed data sets we pool the results as follows. The coeficients are evaluated as $$
\overline{\widehat{\beta}}=\frac{1}{M} \sum_{k=1}^M \widehat{\beta}^k
$$ and an estimate of the covariance matrix of $\overline{\widehat{\beta}}$ is given by $$
V=W+\left(\frac{M+1}{M}\right) B
$$ where $$
W=\frac{1}{M} \sum_{k=1}^M U^k \text { and } B=\frac{1}{M-1} \sum_{k=1}^M\left(\widehat{\beta}^k-\overline{\widehat{\beta}}\right)\left(\widehat{\beta}^k-\overline{\widehat{\beta}}\right)^{\prime}
$$ here, $W$ measures the within-imputation variability and $B$ measures the between-imputation variability. The between-imputation variability is much larger, and it decreases if we reduce the number of imputed values.

```{r include=FALSE, cache = TRUE}
df <- data.frame("Intercept" = rep(NA, 80),
               "Intercept_var" = rep(NA, 80),
               "age" = rep(NA, 80),
               "age_var" = rep(NA, 80),
               "TIME_discrete" = rep(NA, 80),
               "TIME_discrete_var" = rep(NA, 80),
               "age_sqrd" = rep(NA, 80),
               "age_sqrd_var" = rep(NA, 80),
               "age_TIME" = rep(NA, 80),
               "age_TIME_var" = rep(NA, 80),
               "learning" = rep(NA, 80),
               "learning_var" = rep(NA, 80),
               "resid" = rep(NA, 80))

for (i in 1:20) {
  mf <- as.formula(paste(colnames(data_imp_mean[7 + i]),
                         "~ age+TIME_discrete +age:TIME_discrete+ I(age^2)")) #+learninh
  gee1 <- geeglm(mf, 
                 data = data_imp_mean, 
                 id = id,
                 family = "gaussian",
                 corstr = "independence")
  
  df[i,1] <- summary(gee1)[["coefficients"]][[1]][[1]]
  df[i,2] <- summary(gee1)[["coefficients"]][[2]][[1]]^2
  df[i,3] <- summary(gee1)[["coefficients"]][[1]][[2]]
  df[i,4] <- summary(gee1)[["coefficients"]][[2]][[2]]^2
  df[i,5] <- summary(gee1)[["coefficients"]][[1]][[3]]
  df[i,6] <- summary(gee1)[["coefficients"]][[2]][[3]]^2
  df[i,7] <- summary(gee1)[["coefficients"]][[1]][[4]]
  df[i,8] <- summary(gee1)[["coefficients"]][[2]][[4]]^2
  df[i,9] <- summary(gee1)[["coefficients"]][[1]][[5]]
  df[i,10] <- summary(gee1)[["coefficients"]][[2]][[5]]^2
  #df[i,11]<-summary(gee1)[["coefficients"]][[1]][[6]]
  #df[i,12]<-summary(gee1)[["coefficients"]][[2]][[6]]^2
  #df[i,13]<-mean(sqrt(resid(gee1)^2))
  df[i,13] <- mean(na.omit(sqrt(resid(gee1)[!is.na(data_grid$y)]^2)))
    
  gee2 <- geeglm(mf, 
                 data = data_imp_norm, 
                 id = id,
                 family = "gaussian",
                 corstr = "independence")
  j <- i + 20
  df[j,1] <- summary(gee2)[["coefficients"]][[1]][[1]]
  df[j,2] <- summary(gee2)[["coefficients"]][[2]][[1]]^2
  df[j,3] <- summary(gee2)[["coefficients"]][[1]][[2]]
  df[j,4] <- summary(gee2)[["coefficients"]][[2]][[2]]^2
  df[j,5] <- summary(gee2)[["coefficients"]][[1]][[3]]
  df[j,6] <- summary(gee2)[["coefficients"]][[2]][[3]]^2
  df[j,7] <- summary(gee2)[["coefficients"]][[1]][[4]]
  df[j,8] <- summary(gee2)[["coefficients"]][[2]][[4]]^2
  df[j,9] <- summary(gee2)[["coefficients"]][[1]][[5]]
  df[j,10] <- summary(gee2)[["coefficients"]][[2]][[5]]^2
  #df[j,11]<-summary(gee2)[["coefficients"]][[1]][[6]]
  #df[j,12]<-summary(gee2)[["coefficients"]][[2]][[6]]^2
  #df[j,13]<-mean(na.omit(sqrt(resid(gee2)[!is.na(data_grid$y)]^2)))
  df[j,13] <- mean(sqrt(resid(gee2)^2))
  
  gee3 <- geeglm(mf, 
                 data = data_imp_pmm, 
                 id = id,
                 family = "gaussian",
                 corstr = "independence")
  k <- i + 40
  df[k,1] <- summary(gee3)[["coefficients"]][[1]][[1]]
  df[k,2] <- summary(gee3)[["coefficients"]][[2]][[1]]^2
  df[k,3] <- summary(gee3)[["coefficients"]][[1]][[2]]
  df[k,4] <- summary(gee3)[["coefficients"]][[2]][[2]]^2
  df[k,5] <- summary(gee3)[["coefficients"]][[1]][[3]]
  df[k,6] <- summary(gee3)[["coefficients"]][[2]][[3]]^2
  df[k,7] <- summary(gee3)[["coefficients"]][[1]][[4]]
  df[k,8] <- summary(gee3)[["coefficients"]][[2]][[4]]^2
  df[k,9] <- summary(gee3)[["coefficients"]][[1]][[5]]
  df[k,10] <- summary(gee3)[["coefficients"]][[2]][[5]]^2
  #df[k,11]<-summary(gee3)[["coefficients"]][[1]][[6]]
  #df[k,12]<-summary(gee3)[["coefficients"]][[2]][[6]]^2
  #df[k,13]<-mean(na.omit(sqrt(resid(gee3)[!is.na(data_grid$y)]^2)))
  df[k,13] <- mean(sqrt(resid(gee3)^2))
  
  gee4 <- geeglm(mf, 
                 data = data_imp_rf, 
                 id = id,
                 family = "gaussian",
                 corstr = "independence")
  l <- i + 60
  df[l,1] <- summary(gee4)[["coefficients"]][[1]][[1]]
  df[l,2] <- summary(gee4)[["coefficients"]][[2]][[1]]^2
  df[l,3] <- summary(gee4)[["coefficients"]][[1]][[2]]
  df[l,4] <- summary(gee4)[["coefficients"]][[2]][[2]]^2
  df[l,5] <- summary(gee4)[["coefficients"]][[1]][[3]]
  df[l,6] <- summary(gee4)[["coefficients"]][[2]][[3]]^2
  df[l,7] <- summary(gee4)[["coefficients"]][[1]][[4]]
  df[l,8] <- summary(gee4)[["coefficients"]][[2]][[4]]^2
  df[l,9] <- summary(gee4)[["coefficients"]][[1]][[5]]
  df[l,10] <- summary(gee4)[["coefficients"]][[2]][[5]]^2
  #df[l,11]<-summary(gee4)[["coefficients"]][[1]][[6]]
  #df[l,12]<-summary(gee4)[["coefficients"]][[2]][[6]]^2
  #df[l,13]<-mean(na.omit(sqrt(resid(gee4)[!is.na(data_grid$y)]^2)))
  df[l,13] <- mean(sqrt(resid(gee4)^2))
  
}


row_odd <- seq_len(nrow(df)) %% 2
df_monotone <- df[row_odd == 1, ]
df_full <- df[row_odd == 0, ]




Intercept_df <- mean(df$Intercept)
age_df <- mean(df$age)
TIME_discrete_df <- mean(df$TIME_discrete)
learning_df <- mean(df$learning)
age_sqrd_df <- mean(df$age_sqrd)
age_TIME_df <- mean(df$age_TIME)
learning_df <- mean(df$learning)
residuals_mult <- mean(df$resid)


Intercept_df_var <- mean(df$Intercept_var) + (81/80) * var(df$Intercept)
age_df_var <- mean(df$age_var) + (81/80) * var(df$age)
TIME_discrete_df_var <- mean(df$TIME_discrete_var) + (81/80) *
  var(df$TIME_discrete)
age_sqrd_df_var <- mean(df$age_sqrd_var) + (81/80) * var(df$age_sqrd)
age_TIME_df_var <- mean(df$age_TIME_var) + (81/80) * var(df$age_TIME)
learning_df_var <- mean(df$learning_var) + (81/80) * var(df$learning_var)

d2 <- d
d2[1,1] <- Intercept_df
d2[1,2] <- sqrt(Intercept_df_var)
d2[2,1] <- age_df
d2[2,2] <- sqrt(age_df_var)
d2[3,1] <- TIME_discrete_df
d2[3,2] <- sqrt(TIME_discrete_df_var)
d2[4,1] <- age_sqrd_df
d2[4,2] <- sqrt(age_sqrd_df_var)
#d2[5,1]<-learning_df
#d2[5,2]<-sqrt(learning_df_var)
d2[5,1] <- age_TIME_df
d2[5,2] <- sqrt(age_TIME_df_var)

d2 <- d2 %>% 
  mutate(across(where(is.numeric), round, digits = 3))

d2[6,] <- c("RMSE", round(residuals_mult, 3))
row.names(d2)[6] <- " "



Intercept_mon <- mean(df_monotone$Intercept)
age_mon <- mean(df_monotone$age)
TIME_discrete_mon <- mean(df_monotone$TIME_discrete)
learning_mon <- mean(df_monotone$learning)
age_sqrd_mon <- mean(df_monotone$age_sqrd)
age_TIME_mon <- mean(df_monotone$age_TIME)
learning_mon <- mean(df_monotone$learning)
residuals_mult_mon <- mean(df_monotone$resid)

Intercept_df_var_mon <- mean(df_monotone$Intercept_var) + (41/40) * 
  var(df_monotone$Intercept)
age_df_var_mon <- mean(df_monotone$age_var) + (41/40) * var(df_monotone$age)
TIME_discrete_df_var_mon <- mean(df_monotone$TIME_discrete_var) + (41/40) * 
  var(df_monotone$TIME_discrete)
age_sqrd_df_var_mon <- mean(df_monotone$age_sqrd_var) + (41/40) * 
  var(df_monotone$age_sqrd)
age_TIME_df_var_mon <- mean(df_monotone$age_TIME_var) + (41/40) *
  var(df_monotone$age_TIME)
learning_df_var_mon <- mean(df_monotone$learning_var) + (41/40) *
  var(df_monotone$learning_var)

d3 <- d
d3[1,1] <- Intercept_mon
d3[1,2] <- sqrt(Intercept_df_var_mon)
d3[2,1] <- age_mon
d3[2,2] <- sqrt(age_df_var_mon)
d3[3,1] <- TIME_discrete_mon
d3[3,2] <- sqrt(TIME_discrete_df_var_mon)
d3[4,1] <- age_sqrd_mon
d3[4,2] <- sqrt(age_sqrd_df_var_mon)
#d3[5,1]<-learning_mon
#d3[5,2]<-sqrt(learning_df_var_mon)
d3[5,1] <- age_TIME_mon
d3[5,2] <- sqrt(age_TIME_df_var_mon)


d3 <- d3 %>% 
  mutate(across(where(is.numeric), round, digits = 3))

d3[6,] <- c("RMSE", round(residuals_mult_mon, 3))
row.names(d3)[6] <- " "

Intercept_full <- mean(df_full$Intercept)
age_full <- mean(df_full$age)
TIME_discrete_full <- mean(df_full$TIME_discrete)
learning_full <- mean(df_full$learning)
age_sqrd_full <- mean(df_full$age_sqrd)
age_TIME_full <- mean(df_full$age_TIME)
learning_full <- mean(df_monotone$learning)
residuals_mult_full <- mean(df_full$resid)

Intercept_df_var_full <- mean(df_full$Intercept_var) + (41/40) *
  var(df_full$Intercept)
age_df_var_full <- mean(df_full$age_var) + (41/40) * var(df_full$age)
TIME_discrete_df_var_full <- mean(df_full$TIME_discrete_var) + (41/40) * 
  var(df_full$TIME_discrete)
age_sqrd_df_var_full <- mean(df_full$age_sqrd_var) + (41/40) * 
  var(df_full$age_sqrd)
age_TIME_df_var_full <- mean(df_full$age_TIME_var) + (41/40) *
  var(df_full$age_TIME)
learning_df_var_full <- mean(df_full$learning_var) + (41/40) * 
  var(df_full$learning_var)

d4 <- d
d4[1,1] <- Intercept_full
d4[1,2] <- sqrt(Intercept_df_var_full)
d4[2,1] <- age_full
d4[2,2] <- sqrt(age_df_var_full)
d4[3,1] <- TIME_discrete_full
d4[3,2] <- sqrt(TIME_discrete_df_var_full)
d4[4,1] <- age_sqrd_full
d4[4,2] <- sqrt(age_sqrd_df_var_full)
#d4[5,1]<-learning_full
#d4[5,2]<-sqrt(learning_df_var_full)
d4[5,1] <- age_TIME_full
d4[5,2] <- sqrt(age_TIME_df_var_full)

d4 <- d4 %>% 
  mutate(across(where(is.numeric), round, digits = 3))

d4[6,] <- c("RMSE", round(residuals_mult_full, 3))
row.names(d4)[6] <- " "

d5 <- cbind(d1, d2, d3, d4)
d6 <- cbind(rownames(d5), d5)
colnames(d6)[1] <- ""
#d6<-d6[-5,]




```

```{r include=FALSE, cache = TRUE}
###mean
Intercept_df<-mean(df$Intercept[1:20])
age_df<-mean(df$age[1:20])
TIME_discrete_df<-mean(df$TIME_discrete[1:20])
learning_df<-mean(df$learning[1:20])
age_sqrd_df<-mean(df$age_sqrd[1:20])
age_TIME_df<-mean(df$age_TIME[1:20])
learning_df<-mean(df$learning[1:20])
residuals_mult<-mean(df$resid[1:20])


Intercept_df_var<-mean(df$Intercept_var[1:20])+(81/80)*var(df$Intercept[1:20])
age_df_var<-mean(df$age_var[1:20])+(81/80)*var(df$age[1:20])
TIME_discrete_df_var<-mean(df$TIME_discrete_var[1:20])+(81/80)*var(df$TIME_discrete[1:20])
age_sqrd_df_var<-mean(df$age_sqrd_var[1:20])+(81/80)*var(df$age_sqrd[1:20])
age_TIME_df_var<-mean(df$age_TIME_var[1:20])+(81/80)*var(df$age_TIME[1:20])
learning_df_var<-mean(df$learning_var[1:20])+(81/80)*var(df$learning_var[1:20])

d2_mean<-d
d2_mean[1,1]<-Intercept_df
d2_mean[1,2]<-sqrt(Intercept_df_var)
d2_mean[2,1]<-age_df
d2_mean[2,2]<-sqrt(age_df_var)
d2_mean[3,1]<-TIME_discrete_df
d2_mean[3,2]<-sqrt(TIME_discrete_df_var)
d2_mean[4,1]<-age_sqrd_df
d2_mean[4,2]<-sqrt(age_sqrd_df_var)
#d2_mean[5,1]<-learning_df
#d2_mean[5,2]<-sqrt(learning_df_var)
d2_mean[5,1]<-age_TIME_df
d2_mean[5,2]<-sqrt(age_TIME_df_var)

d2_mean<-d2_mean %>% 
  mutate(across(where(is.numeric), round, digits=3))

d2_mean[6,]<-c("RMSE",round(residuals_mult,3))
row.names(d2_mean)[6]<-" "

###norm
Intercept_df<-mean(df$Intercept[21:40])
age_df<-mean(df$age[21:40])
TIME_discrete_df<-mean(df$TIME_discrete[21:40])
learning_df<-mean(df$learning[21:40])
age_sqrd_df<-mean(df$age_sqrd[21:40])
age_TIME_df<-mean(df$age_TIME[21:40])
learning_df<-mean(df$learning[21:40])
residuals_mult<-mean(df$resid[21:40])


Intercept_df_var<-mean(df$Intercept_var[21:40])+(81/80)*var(df$Intercept[21:40])
age_df_var<-mean(df$age_var[21:40])+(81/80)*var(df$age[21:40])
TIME_discrete_df_var<-mean(df$TIME_discrete_var[21:40])+(81/80)*var(df$TIME_discrete[21:40])
age_sqrd_df_var<-mean(df$age_sqrd_var[21:40])+(81/80)*var(df$age_sqrd[21:40])
age_TIME_df_var<-mean(df$age_TIME_var[21:40])+(81/80)*var(df$age_TIME[21:40])
learning_df_var<-mean(df$learning_var[21:40])+(81/80)*var(df$learning_var[21:40])

d2_norm<-d
d2_norm[1,1]<-Intercept_df
d2_norm[1,2]<-sqrt(Intercept_df_var)
d2_norm[2,1]<-age_df
d2_norm[2,2]<-sqrt(age_df_var)
d2_norm[3,1]<-TIME_discrete_df
d2_norm[3,2]<-sqrt(TIME_discrete_df_var)
d2_norm[4,1]<-age_sqrd_df
d2_norm[4,2]<-sqrt(age_sqrd_df_var)
#d2_norm[5,1]<-learning_df
#d2_norm[5,2]<-sqrt(learning_df_var)
d2_norm[5,1]<-age_TIME_df
d2_norm[5,2]<-sqrt(age_TIME_df_var)

d2_norm<-d2_norm %>% 
  mutate(across(where(is.numeric), round, digits=3))

d2_norm[6,]<-c("RMSE",round(residuals_mult,3))
row.names(d2_norm)[6]<-" "

###pmm
Intercept_df<-mean(df$Intercept[41:60])
age_df<-mean(df$age[41:60])
TIME_discrete_df<-mean(df$TIME_discrete[41:60])
learning_df<-mean(df$learning[41:60])
age_sqrd_df<-mean(df$age_sqrd[41:60])
age_TIME_df<-mean(df$age_TIME[41:60])
learning_df<-mean(df$learning[41:60])
residuals_mult<-mean(df$resid[41:60])


Intercept_df_var<-mean(df$Intercept_var[41:60])+(81/80)*var(df$Intercept[41:60])
age_df_var<-mean(df$age_var[41:60])+(81/80)*var(df$age[41:60])
TIME_discrete_df_var<-mean(df$TIME_discrete_var[41:60])+(81/80)*var(df$TIME_discrete[41:60])
age_sqrd_df_var<-mean(df$age_sqrd_var[41:60])+(81/80)*var(df$age_sqrd[41:60])
age_TIME_df_var<-mean(df$age_TIME_var[41:60])+(81/80)*var(df$age_TIME[41:60])
learning_df_var<-mean(df$learning_var[41:60])+(81/80)*var(df$learning_var[41:60])

d2_pmm<-d
d2_pmm[1,1]<-Intercept_df
d2_pmm[1,2]<-sqrt(Intercept_df_var)
d2_pmm[2,1]<-age_df
d2_pmm[2,2]<-sqrt(age_df_var)
d2_pmm[3,1]<-TIME_discrete_df
d2_pmm[3,2]<-sqrt(TIME_discrete_df_var)
d2_pmm[4,1]<-age_sqrd_df
d2_pmm[4,2]<-sqrt(age_sqrd_df_var)
#d2_pmm[5,1]<-learning_df
#d2_pmm[5,2]<-sqrt(learning_df_var)
d2_pmm[5,1]<-age_TIME_df
d2_pmm[5,2]<-sqrt(age_TIME_df_var)

d2_pmm<-d2_pmm %>% 
  mutate(across(where(is.numeric), round, digits=3))

d2_pmm[6,]<-c("RMSE",round(residuals_mult,3))
row.names(d2_pmm)[6]<-" "

###rf
Intercept_df<-mean(df$Intercept[61:80])
age_df<-mean(df$age[61:80])
TIME_discrete_df<-mean(df$TIME_discrete[61:80])
learning_df<-mean(df$learning[61:80])
age_sqrd_df<-mean(df$age_sqrd[61:80])
age_TIME_df<-mean(df$age_TIME[61:80])
learning_df<-mean(df$learning[61:80])
residuals_mult<-mean(df$resid[61:80])


Intercept_df_var<-mean(df$Intercept_var[61:80])+(81/80)*var(df$Intercept[61:80])
age_df_var<-mean(df$age_var[61:80])+(81/80)*var(df$age[61:80])
TIME_discrete_df_var<-mean(df$TIME_discrete_var[61:80])+(81/80)*var(df$TIME_discrete[61:80])
age_sqrd_df_var<-mean(df$age_sqrd_var[61:80])+(81/80)*var(df$age_sqrd[61:80])
age_TIME_df_var<-mean(df$age_TIME_var[61:80])+(81/80)*var(df$age_TIME[61:80])
learning_df_var<-mean(df$learning_var[61:80])+(81/80)*var(df$learning_var[61:80])

d2_rf<-d
d2_rf[1,1]<-Intercept_df
d2_rf[1,2]<-sqrt(Intercept_df_var)
d2_rf[2,1]<-age_df
d2_rf[2,2]<-sqrt(age_df_var)
d2_rf[3,1]<-TIME_discrete_df
d2_rf[3,2]<-sqrt(TIME_discrete_df_var)
d2_rf[4,1]<-age_sqrd_df
d2_rf[4,2]<-sqrt(age_sqrd_df_var)
#d2_rf[5,1]<-learning_df
#d2_rf[5,2]<-sqrt(learning_df_var)
d2_rf[5,1]<-age_TIME_df
d2_rf[5,2]<-sqrt(age_TIME_df_var)

d2_rf<-d2_rf %>% 
  mutate(across(where(is.numeric), round, digits=3))

d2_rf[6,]<-c("RMSE",round(residuals_mult,3))
row.names(d2_rf)[6]<-" "

d5a<-cbind(d2_mean,d2_norm,d2_pmm,d2_rf)
d6a<-cbind(rownames(d5a),d5a)
colnames(d6a)[1]<-""


```

```{r include=FALSE, cache = TRUE}

###Mean
Intercept_mon<-mean(df_monotone$Intercept[1:10])
age_mon<-mean(df_monotone$age[1:10])
TIME_discrete_mon<-mean(df_monotone$TIME_discrete[1:10])
learning_mon<-mean(df_monotone$learning[1:10])
age_sqrd_mon<-mean(df_monotone$age_sqrd[1:10])
age_TIME_mon<-mean(df_monotone$age_TIME[1:10])
learning_mon<-mean(df_monotone$learning[1:10])
residuals_mult_mon<-mean(df_monotone$resid[1:10])

Intercept_df_var_mon<-mean(df_monotone$Intercept_var[1:10])+(41/40)*var(df_monotone$Intercept[1:10])
age_df_var_mon<-mean(df_monotone$age_var[1:10])+(41/40)*var(df_monotone$age[1:10])
TIME_discrete_df_var_mon<-mean(df_monotone$TIME_discrete_var[1:10])+(41/40)*var(df_monotone$TIME_discrete[1:10])
age_sqrd_df_var_mon<-mean(df_monotone$age_sqrd_var[1:10])+(41/40)*var(df_monotone$age_sqrd[1:10])
age_TIME_df_var_mon<-mean(df_monotone$age_TIME_var[1:10])+(41/40)*var(df_monotone$age_TIME[1:10])
learning_df_var_mon<-mean(df_monotone$learning_var[1:10])+(41/40)*var(df_monotone$learning_var[1:10])

d3_mean<-d
d3_mean[1,1]<-Intercept_mon
d3_mean[1,2]<-sqrt(Intercept_df_var_mon)
d3_mean[2,1]<-age_mon
d3_mean[2,2]<-sqrt(age_df_var_mon)
d3_mean[3,1]<-TIME_discrete_mon
d3_mean[3,2]<-sqrt(TIME_discrete_df_var_mon)
d3_mean[4,1]<-age_sqrd_mon
d3_mean[4,2]<-sqrt(age_sqrd_df_var_mon)
#d3_mean[5,1]<-learning_mon
#d3_mean[5,2]<-sqrt(learning_df_var_mon)
d3_mean[5,1]<-age_TIME_mon
d3_mean[5,2]<-sqrt(age_TIME_df_var_mon)


d3_mean<-d3_mean %>% 
  mutate(across(where(is.numeric), round, digits=3))

d3_mean[6,]<-c("RMSE",round(residuals_mult_mon,3))
row.names(d3_mean)[6]<-" "


###norm
Intercept_mon<-mean(df_monotone$Intercept[11:20])
age_mon<-mean(df_monotone$age[11:20])
TIME_discrete_mon<-mean(df_monotone$TIME_discrete[11:20])
learning_mon<-mean(df_monotone$learning[11:20])
age_sqrd_mon<-mean(df_monotone$age_sqrd[11:20])
age_TIME_mon<-mean(df_monotone$age_TIME[11:20])
learning_mon<-mean(df_monotone$learning[11:20])
residuals_mult_mon<-mean(df_monotone$resid[11:20])

Intercept_df_var_mon<-mean(df_monotone$Intercept_var[11:20])+(41/40)*var(df_monotone$Intercept[11:20])
age_df_var_mon<-mean(df_monotone$age_var[11:20])+(41/40)*var(df_monotone$age[11:20])
TIME_discrete_df_var_mon<-mean(df_monotone$TIME_discrete_var[11:20])+(41/40)*var(df_monotone$TIME_discrete[11:20])
age_sqrd_df_var_mon<-mean(df_monotone$age_sqrd_var[11:20])+(41/40)*var(df_monotone$age_sqrd[11:20])
age_TIME_df_var_mon<-mean(df_monotone$age_TIME_var[11:20])+(41/40)*var(df_monotone$age_TIME[11:20])
learning_df_var_mon<-mean(df_monotone$learning_var[11:20])+(41/40)*var(df_monotone$learning_var[11:20])

d3_norm<-d
d3_norm[1,1]<-Intercept_mon
d3_norm[1,2]<-sqrt(Intercept_df_var_mon)
d3_norm[2,1]<-age_mon
d3_norm[2,2]<-sqrt(age_df_var_mon)
d3_norm[3,1]<-TIME_discrete_mon
d3_norm[3,2]<-sqrt(TIME_discrete_df_var_mon)
d3_norm[4,1]<-age_sqrd_mon
d3_norm[4,2]<-sqrt(age_sqrd_df_var_mon)
#d3_norm[5,1]<-learning_mon
#d3_norm[5,2]<-sqrt(learning_df_var_mon)
d3_norm[5,1]<-age_TIME_mon
d3_norm[5,2]<-sqrt(age_TIME_df_var_mon)


d3_norm<-d3_norm %>% 
  mutate(across(where(is.numeric), round, digits=3))

d3_norm[6,]<-c("RMSE",round(residuals_mult_mon,3))
row.names(d3)[6]<-" "

###pmm
Intercept_mon<-mean(df_monotone$Intercept[21:30])
age_mon<-mean(df_monotone$age[21:30])
TIME_discrete_mon<-mean(df_monotone$TIME_discrete[21:30])
learning_mon<-mean(df_monotone$learning[21:30])
age_sqrd_mon<-mean(df_monotone$age_sqrd[21:30])
age_TIME_mon<-mean(df_monotone$age_TIME[21:30])
learning_mon<-mean(df_monotone$learning[21:30])
residuals_mult_mon<-mean(df_monotone$resid[21:30])

Intercept_df_var_mon<-mean(df_monotone$Intercept_var[21:30])+(41/40)*var(df_monotone$Intercept[21:30])
age_df_var_mon<-mean(df_monotone$age_var[21:30])+(41/40)*var(df_monotone$age[21:30])
TIME_discrete_df_var_mon<-mean(df_monotone$TIME_discrete_var[21:30])+(41/40)*var(df_monotone$TIME_discrete[21:30])
age_sqrd_df_var_mon<-mean(df_monotone$age_sqrd_var[21:30])+(41/40)*var(df_monotone$age_sqrd[21:30])
age_TIME_df_var_mon<-mean(df_monotone$age_TIME_var[21:30])+(41/40)*var(df_monotone$age_TIME[21:30])
learning_df_var_mon<-mean(df_monotone$learning_var[21:30])+(41/40)*var(df_monotone$learning_var[21:30])

d3_pmm<-d
d3_pmm[1,1]<-Intercept_mon
d3_pmm[1,2]<-sqrt(Intercept_df_var_mon)
d3_pmm[2,1]<-age_mon
d3_pmm[2,2]<-sqrt(age_df_var_mon)
d3_pmm[3,1]<-TIME_discrete_mon
d3_pmm[3,2]<-sqrt(TIME_discrete_df_var_mon)
d3_pmm[4,1]<-age_sqrd_mon
d3_pmm[4,2]<-sqrt(age_sqrd_df_var_mon)
#d3_pmm[5,1]<-learning_mon
#d3_pmm[5,2]<-sqrt(learning_df_var_mon)
d3_pmm[5,1]<-age_TIME_mon
d3_pmm[5,2]<-sqrt(age_TIME_df_var_mon)


d3_pmm<-d3_pmm %>% 
  mutate(across(where(is.numeric), round, digits=3))

d3_pmm[6,]<-c("RMSE",round(residuals_mult_mon,3))
row.names(d3_pmm)[6]<-" "


###rf
Intercept_mon<-mean(df_monotone$Intercept[31:40])
age_mon<-mean(df_monotone$age[31:40])
TIME_discrete_mon<-mean(df_monotone$TIME_discrete[31:40])
learning_mon<-mean(df_monotone$learning[31:40])
age_sqrd_mon<-mean(df_monotone$age_sqrd[31:40])
age_TIME_mon<-mean(df_monotone$age_TIME[31:40])
learning_mon<-mean(df_monotone$learning[31:40])
residuals_mult_mon<-mean(df_monotone$resid[31:40])

Intercept_df_var_mon<-mean(df_monotone$Intercept_var[31:40])+(41/40)*var(df_monotone$Intercept[31:40])
age_df_var_mon<-mean(df_monotone$age_var[31:40])+(41/40)*var(df_monotone$age[31:40])
TIME_discrete_df_var_mon<-mean(df_monotone$TIME_discrete_var[31:40])+(41/40)*var(df_monotone$TIME_discrete[31:40])
age_sqrd_df_var_mon<-mean(df_monotone$age_sqrd_var[31:40])+(41/40)*var(df_monotone$age_sqrd[31:40])
age_TIME_df_var_mon<-mean(df_monotone$age_TIME_var[31:40])+(41/40)*var(df_monotone$age_TIME[31:40])
learning_df_var_mon<-mean(df_monotone$learning_var[31:40])+(41/40)*var(df_monotone$learning_var[31:40])

d3_rf<-d
d3_rf[1,1]<-Intercept_mon
d3_rf[1,2]<-sqrt(Intercept_df_var_mon)
d3_rf[2,1]<-age_mon
d3_rf[2,2]<-sqrt(age_df_var_mon)
d3_rf[3,1]<-TIME_discrete_mon
d3_rf[3,2]<-sqrt(TIME_discrete_df_var_mon)
d3_rf[4,1]<-age_sqrd_mon
d3_rf[4,2]<-sqrt(age_sqrd_df_var_mon)
#d3_rf[5,1]<-learning_mon
#d3_rf[5,2]<-sqrt(learning_df_var_mon)
d3_rf[5,1]<-age_TIME_mon
d3_rf[5,2]<-sqrt(age_TIME_df_var_mon)


d3_rf<-d3_rf %>% 
  mutate(across(where(is.numeric), round, digits=3))

d3_rf[6,]<-c("RMSE",round(residuals_mult_mon,3))
row.names(d3_rf)[6]<-" "


d5b<-cbind(d3_mean,d3_norm,d3_pmm,d3_rf)
d6b<-cbind(rownames(d5b),d5b)
colnames(d6b)[1]<-""


```

```{r include=FALSE, cache = TRUE}
###mean
Intercept_full<-mean(df_full$Intercept[1:10])
age_full<-mean(df_full$age[1:10])
TIME_discrete_full<-mean(df_full$TIME_discrete[1:10])
learning_full<-mean(df_full$learning[1:10])
age_sqrd_full<-mean(df_full$age_sqrd[1:10])
age_TIME_full<-mean(df_full$age_TIME[1:10])
learning_full<-mean(df_monotone$learning[1:10])
residuals_mult_full<-mean(df_full$resid[1:10])

Intercept_df_var_full<-mean(df_full$Intercept_var[1:10])+(41/40)*var(df_full$Intercept[1:10])
age_df_var_full<-mean(df_full$age_var[1:10])+(41/40)*var(df_full$age[1:10])
TIME_discrete_df_var_full<-mean(df_full$TIME_discrete_var[1:10])+(41/40)*var(df_full$TIME_discrete[1:10])
age_sqrd_df_var_full<-mean(df_full$age_sqrd_var[1:10])+(41/40)*var(df_full$age_sqrd[1:10])
age_TIME_df_var_full<-mean(df_full$age_TIME_var[1:10])+(41/40)*var(df_full$age_TIME[1:10])
learning_df_var_full<-mean(df_full$learning_var[1:10])+(41/40)*var(df_full$learning_var[1:10])

d4_mean<-d
d4_mean[1,1]<-Intercept_full
d4_mean[1,2]<-sqrt(Intercept_df_var_full)
d4_mean[2,1]<-age_full
d4_mean[2,2]<-sqrt(age_df_var_full)
d4_mean[3,1]<-TIME_discrete_full
d4_mean[3,2]<-sqrt(TIME_discrete_df_var_full)
d4_mean[4,1]<-age_sqrd_full
d4_mean[4,2]<-sqrt(age_sqrd_df_var_full)
#d4_mean[5,1]<-learning_full
#d4_mean[5,2]<-sqrt(learning_df_var_full)
d4_mean[5,1]<-age_TIME_full
d4_mean[5,2]<-sqrt(age_TIME_df_var_full)

d4_mean<-d4_mean %>% 
  mutate(across(where(is.numeric), round, digits=3))

d4_mean[6,]<-c("RMSE",round(residuals_mult_full,3))
row.names(d4_mean)[6]<-" "

###norm
Intercept_full<-mean(df_full$Intercept[11:20])
age_full<-mean(df_full$age[11:20])
TIME_discrete_full<-mean(df_full$TIME_discrete[11:20])
learning_full<-mean(df_full$learning[11:20])
age_sqrd_full<-mean(df_full$age_sqrd[11:20])
age_TIME_full<-mean(df_full$age_TIME[11:20])
learning_full<-mean(df_monotone$learning[11:20])
residuals_mult_full<-mean(df_full$resid[11:20])

Intercept_df_var_full<-mean(df_full$Intercept_var[11:20])+(41/40)*var(df_full$Intercept[11:20])
age_df_var_full<-mean(df_full$age_var[11:20])+(41/40)*var(df_full$age[11:20])
TIME_discrete_df_var_full<-mean(df_full$TIME_discrete_var[11:20])+(41/40)*var(df_full$TIME_discrete[11:20])
age_sqrd_df_var_full<-mean(df_full$age_sqrd_var[11:20])+(41/40)*var(df_full$age_sqrd[11:20])
age_TIME_df_var_full<-mean(df_full$age_TIME_var[11:20])+(41/40)*var(df_full$age_TIME[11:20])
learning_df_var_full<-mean(df_full$learning_var[11:20])+(41/40)*var(df_full$learning_var[11:20])

d4_norm<-d
d4_norm[1,1]<-Intercept_full
d4_norm[1,2]<-sqrt(Intercept_df_var_full)
d4_norm[2,1]<-age_full
d4_norm[2,2]<-sqrt(age_df_var_full)
d4_norm[3,1]<-TIME_discrete_full
d4_norm[3,2]<-sqrt(TIME_discrete_df_var_full)
d4_norm[4,1]<-age_sqrd_full
d4_norm[4,2]<-sqrt(age_sqrd_df_var_full)
#d4_norm[5,1]<-learning_full
#d4_norm[5,2]<-sqrt(learning_df_var_full)
d4_norm[5,1]<-age_TIME_full
d4_norm[5,2]<-sqrt(age_TIME_df_var_full)

d4_norm<-d4_norm %>% 
  mutate(across(where(is.numeric), round, digits=3))

d4_norm[6,]<-c("RMSE",round(residuals_mult_full,3))
row.names(d4_norm)[6]<-" "


###pmm
Intercept_full<-mean(df_full$Intercept[21:30])
age_full<-mean(df_full$age[21:30])
TIME_discrete_full<-mean(df_full$TIME_discrete[21:30])
learning_full<-mean(df_full$learning[21:30])
age_sqrd_full<-mean(df_full$age_sqrd[21:30])
age_TIME_full<-mean(df_full$age_TIME[21:30])
learning_full<-mean(df_monotone$learning[21:30])
residuals_mult_full<-mean(df_full$resid[21:30])

Intercept_df_var_full<-mean(df_full$Intercept_var[21:30])+(41/40)*var(df_full$Intercept[21:30])
age_df_var_full<-mean(df_full$age_var[21:30])+(41/40)*var(df_full$age[21:30])
TIME_discrete_df_var_full<-mean(df_full$TIME_discrete_var[21:30])+(41/40)*var(df_full$TIME_discrete[21:30])
age_sqrd_df_var_full<-mean(df_full$age_sqrd_var[21:30])+(41/40)*var(df_full$age_sqrd[21:30])
age_TIME_df_var_full<-mean(df_full$age_TIME_var[21:30])+(41/40)*var(df_full$age_TIME[21:30])
learning_df_var_full<-mean(df_full$learning_var[21:30])+(41/40)*var(df_full$learning_var[21:30])

d4_pmm<-d
d4_pmm[1,1]<-Intercept_full
d4_pmm[1,2]<-sqrt(Intercept_df_var_full)
d4_pmm[2,1]<-age_full
d4_pmm[2,2]<-sqrt(age_df_var_full)
d4_pmm[3,1]<-TIME_discrete_full
d4_pmm[3,2]<-sqrt(TIME_discrete_df_var_full)
d4_pmm[4,1]<-age_sqrd_full
d4_pmm[4,2]<-sqrt(age_sqrd_df_var_full)
#d4_pmm[5,1]<-learning_full
#d4_pmm[5,2]<-sqrt(learning_df_var_full)
d4_pmm[5,1]<-age_TIME_full
d4_pmm[5,2]<-sqrt(age_TIME_df_var_full)

d4_pmm<-d4_pmm %>% 
  mutate(across(where(is.numeric), round, digits=3))

d4_pmm[6,]<-c("RMSE",round(residuals_mult_full,3))
row.names(d4_pmm)[6]<-" "


###rf
Intercept_full<-mean(df_full$Intercept[31:40])
age_full<-mean(df_full$age[31:40])
TIME_discrete_full<-mean(df_full$TIME_discrete[31:40])
learning_full<-mean(df_full$learning[31:40])
age_sqrd_full<-mean(df_full$age_sqrd[31:40])
age_TIME_full<-mean(df_full$age_TIME[31:40])
learning_full<-mean(df_monotone$learning[31:40])
residuals_mult_full<-mean(df_full$resid[31:40])

Intercept_df_var_full<-mean(df_full$Intercept_var[31:40])+(41/40)*var(df_full$Intercept[31:40])
age_df_var_full<-mean(df_full$age_var[31:40])+(41/40)*var(df_full$age[31:40])
TIME_discrete_df_var_full<-mean(df_full$TIME_discrete_var[31:40])+(41/40)*var(df_full$TIME_discrete[31:40])
age_sqrd_df_var_full<-mean(df_full$age_sqrd_var[31:40])+(41/40)*var(df_full$age_sqrd[31:40])
age_TIME_df_var_full<-mean(df_full$age_TIME_var[31:40])+(41/40)*var(df_full$age_TIME[31:40])
learning_df_var_full<-mean(df_full$learning_var[31:40])+(41/40)*var(df_full$learning_var[31:40])

d4_rf<-d
d4_rf[1,1]<-Intercept_full
d4_rf[1,2]<-sqrt(Intercept_df_var_full)
d4_rf[2,1]<-age_full
d4_rf[2,2]<-sqrt(age_df_var_full)
d4_rf[3,1]<-TIME_discrete_full
d4_rf[3,2]<-sqrt(TIME_discrete_df_var_full)
d4_rf[4,1]<-age_sqrd_full
d4_rf[4,2]<-sqrt(age_sqrd_df_var_full)
#d4_rf[5,1]<-learning_full
#d4_rf[5,2]<-sqrt(learning_df_var_full)
d4_rf[5,1]<-age_TIME_full
d4_rf[5,2]<-sqrt(age_TIME_df_var_full)

d4_rf<-d4_rf %>% 
  mutate(across(where(is.numeric), round, digits=3))

d4_rf[6,]<-c("RMSE",round(residuals_mult_full,3))
row.names(d4_rf)[6]<-" "


d5c<-cbind(d4_mean,d4_norm,d4_pmm,d4_rf)
d6c<-cbind(rownames(d5c),d5c)
colnames(d6c)[1]<-""



```

```{r wGEEvsGEEMI, echo=FALSE}
d6[, 1] <- str_remove(str_remove(d6[, 1], "_discrete"), "TRUE")
d6 %>% as.data.frame() %>%
  kable(booktabs = TRUE,
        row.names = FALSE,
        caption = "Model results for weighted GEE and GEE with MI.") %>%
  add_header_above(c(" ","Weighted GEE" = 2, "MI GEE" = 2, "MI-Mon GEE" = 2, 
                     "MI-FCS GEE" = 2))
```

In Table \@ref(tab:wGEEvsGEEMI) we can see the coefficients for the weighted GEE, the Multiple Imputation GEE based on both monotone and FCS imputation, the MI GEE based only on monotone imputation and finally the MI GEE based only on FCS imputation. At the bottom, we also record the Root Mean Squared Error for each model. We observe that the weighted GEE outperforms all 3 of the MI GEE models. We hypothesize that the reason for this is the large number of values which we needed to impute. Within the MI GEE the one based on monotone imputation performs the best.

```{r GEEMImethods, echo=FALSE}
d6a[, 1] <- str_remove(str_remove(d6a[, 1], "_discrete"), "TRUE")
d6a %>% as.data.frame() %>%
  kable(booktabs = TRUE,
        row.names = FALSE,
        caption = "Model results for different imputation methods.") %>%
  add_header_above(c(" ","MI GEE Mean" = 2, "MI GEE Norm" = 2, "MI GEE Pmm" = 2, 
                     "MI GEE Rf" = 2))
```

Next we will take a look at the performance of the different imputation methods individually. In Table \@ref(tab:GEEMImethods)  we discern between imputation methods but not between monotone or FCS; we average across the 10 monotone AND 10 FCS imputations. We see that the Unconditional mean imputation outperforms the other types of imputation with Random Forest imputation after it with nearly twice as high RMSE. The MI Method with unconditional mean imputation considering both monotone and FCS outperforms the weighted GEE. This gives rise to the question whether or not there is a difference between monotone and FCS imputation between different methods. We can see the results below.

```{r GEEMImonotone, echo=FALSE}
d6b[, 1] <- str_remove(str_remove(d6b[, 1], "_discrete"), "TRUE")
d6b %>% as.data.frame() %>%
  kable(booktabs = TRUE,
        row.names = FALSE,
        caption = "Model results for different imputation methods with monotone imputation.") %>%
  add_header_above(c(" ","MI GEE Mean" = 2, "MI GEE Norm" = 2, 
                     "MI GEE Pmm" = 2, "MI GEE Rf" = 2))
```

```{r GEEMIfull, echo=FALSE}
d6c[, 1] <- str_remove(str_remove(d6c[, 1], "_discrete"), "TRUE")
d6c %>% as.data.frame() %>%
  kable(booktabs = TRUE,
        row.names = FALSE,
        caption = "Model results for different imputation methods with FCS imputation.") %>%
  add_header_above(c(" ","MI GEE Mean" = 2, "MI GEE Norm" = 2, 
                     "MI GEE Pmm" = 2, "MI GEE Rf" = 2))
```

In Table \@ref(tab:GEEMImonotone) and \@ref(tab:GEEMIfull), we compare the monotone and FCS imputation across all 4 different imputation methods. By far the best performing is the unconditional mean monotone imputation. It outperforms every other methodology and is the reason why the averaged unconditional mean method outperformed the weighted GEE.

## Sensitivity analysis

In the previous sections, some sensitivity analysis was done with respect to the different possible imputation methods. Usually, the model results were quite stable. However, all of the previous models assume MAR. In this section, we explore whether the results are robust if the MAR assumption is not realistic and the missingness is not at random (MNAR). Whether or not there is MAR or MNAR cannot be easily and directly tested since we can never know for sure what the hearing threshold would have been if it is missing [@verbeke2001sensitivity; @van2001local]. It is likely that different assumption on the missingness mechanism will lead to different conclusions, especially if the dropout is higher than 10% [@10.3389/fpsyg.2017.00722]. The dropout/missingness is much higher in our dataset and, results are thus expected to be highly impacted.

We use imputation under a MNAR mechanism by the not at random fully conditional specification (NARFCS) procedure [see @tompsett2018use and [this useful vignette]{https://github.com/moreno-betancur/NARFCS/blob/master/Vignette.md}]. This method works, even is the missingness is not monotone, and allows us to test the effect of different shifts in the MNAR imputed values on the model coefficients. These shifts may also depend on other covariates (such as age and time, see the unidentifiable part in the equation below). Notice that the unidentifiable part will only come into play when an observation is missing ($R_y=1$). More concretely, The imputed values are of the following form:

\begin{align} 
{E(Y|X,R_Y)} =&\underbrace{\beta_{Y0}+ \beta_{Yage} age + \beta_{Yage2} age^2 + \beta_{Ytime} TIME + \beta_{Ytimeage} TIME:age}_\text{IDENTIFIABLE PART}\ \\&+\underbrace{R_Y(\delta_{Y0}+\delta_{Yage} age+\delta_{Yage2} age^2 + \delta_{Ytime} TIME + \delta_{Ytimeage} TIME:age)}_\text{UNIDENTIFIABLE PART}. 
\end{align}

In practice, it is suggested that the sensitivity parameters ($\delta$'s) are discussed and chosen with practitioners. For instance, in the hypothetical case that people were asked not let their hearing be measured when they have a cold, the hearing threshold might be higher if the data is missing and practitioners may have some intuition as to how much higher. It should be noted that eliciting these parameters can betricky because they are *conditional* on all other parameters (see also section 5). Here, we don't have any information from practitioners and implement the following shifts as an illustration:

  - A shift in the intercept: $\delta_{Y0} \in \{-5; -2;0;2;5\}$. This means that the imputation for the missing values will differ between -5 to 5 dB from expected values in MAR, on average.
  - A shift in the effect of age $\delta_{Yage} \in \{-1; -0.5;0;0.5;1\}$. 
  - A shift in the effect of time $\delta_{Ytime} \in \{-1; -0.5;0;0.5;1\}$. 

In each of the 125 (5*5*5) scenarios, We will impute the data ten times and will fit a GEE model with a simple correlation structure on the imputed data. Final results in each scenario are then obtained using the same methodology as in section 3.2.2. 

```{r echo=FALSE, eval=!file.exists("data/resultssensitivitywithlearning.Rdata")}
getimputationsummary <- function(data, intercept, deltaage, deltatime, formula, predSens, sensFormula, m){
  nbobs = nrow(data) #nb observation 
  sensFormula <- sprintf("%.1f%+.1f*TIME_discrete%+.1f*age", 
                             intercept, deltaage, deltatime)
   mnar.blot <- list(y = list(ums = sensFormula))
    imputation <- mice(data, m = m,
               method = c("mnar.norm", "", "", "", "", "", ""),
               predictorMatrix = formula,
               predictorSens = predSens,
               blots = mnar.blot, 
               seed = 234235, print = FALSE
               )
    fit <- with(imputation, 
                 geeglm(y ~ age + TIME_discrete + age:TIME_discrete + I(age^2) + learning, 
                 id = id,
                 family = "gaussian",
                 corstr = "independence"))
    res <- summary(pool(fit,
                 rule = "rubin1987")) %>%
      mutate(intercept = intercept,
             deltaage = deltaage,
             deltatime = deltatime,
             lb = estimate + qt(p = .025, df = df)*std.error,
             ub = estimate + qt(p = .975, df = df)*std.error)
    return(res)
}

filtereddata <- data_grid %>%
  dplyr::select(y, TIME_discrete, age, id, learning) %>%
  mutate(age2 = age*age,
         timeage = TIME_discrete*age)
#Set-up predictor matrix for identifiable part
predMatrix <- matrix(rep(0, ncol(filtereddata) * ncol(filtereddata)), 
                     ncol = ncol(filtereddata))
colnames(predMatrix) <- rownames(predMatrix) <- names(filtereddata)
predMatrix["y",] <- c(0, 1, 1, 0, 1, 1, 1)#we're only predicting y with everything except id

predSens <- matrix(rep(0, ncol(filtereddata) * ncol(filtereddata)), 
                   ncol = ncol(filtereddata))
colnames(predSens) <- paste(":", names(filtereddata), sep = "")
rownames(predSens) <- names(filtereddata)
predSens["y",] <- c(0, 1, 1, 0, 0, 0, 0)# we also want to use time and age to predict the unobserved part.
results <- data.frame()
for (intercept in c(-5, -2, 0, 2, 5)) {
  for (deltaage in c(-1, -0.5, 0, 0.5, 1)) {
    for (deltatime in c(-1, -0.5, 0, 0.5, 1)) {
      res <- getimputationsummary(data = filtereddata,
                           intercept = intercept, 
                           deltaage = deltaage, 
                           deltatime = deltatime, 
                           formula = predMatrix,#the observable part
                           predSens = predSens,
                           sensFormula = sensFormula, #unobservable part
                           m = 10)
      results <- rbind(results,res)
    }
  }
}

save(results, file = "data/resultssensitivitywithlearning.Rdata")
```

```{r echo=FALSE, eval=!file.exists("data/resultssensitivity.Rdata")}
getimputationsummary <- function(data, intercept, deltaage, deltatime, formula, predSens, sensFormula, m){
  nbobs = nrow(filtereddata) #nb observation 
  sensFormula <- sprintf("%.1f%+.1f*TIME_discrete%+.1f*age", 
                             intercept, deltaage, deltatime)
   mnar.blot <- list(y = list(ums = sensFormula))
    imputation <- mice(data, m = m,
               method = c("mnar.norm", "", "", "", "", ""),
               predictorMatrix = formula,
               predictorSens = predSens,
               blots = mnar.blot, 
               seed = 234235, print = FALSE
               )
    fit <- with(imputation, 
                 geeglm(y~ age + TIME_discrete + age:TIME_discrete + I(age^2), 
                 id = id,
                 family = "gaussian",
                 corstr = "independence"))
    res <- summary(pool(fit,
                 rule = "rubin1987")) %>%
      mutate(intercept = intercept,
             deltaage = deltaage,
             deltatime = deltatime,
             lb = estimate + qt(p = .025, df = df)*std.error,
             ub = estimate + qt(p = .975, df = df)*std.error)
    return(res)
}

filtereddata <- data_grid %>%
  dplyr::select(y, TIME_discrete, age, id) %>%
  mutate(age2 = age*age,
         timeage = TIME_discrete*age)
#Set-up predictor matrix for identifiable part
predMatrix <- matrix(rep(0, ncol(filtereddata) * ncol(filtereddata)), 
                     ncol = ncol(filtereddata))
colnames(predMatrix) <- rownames(predMatrix) <- names(filtereddata)
predMatrix["y",] <- c(0,1,1,0,1,1)#we're only predicting y with everything except id

predSens <- matrix(rep(0, ncol(filtereddata) * ncol(filtereddata)), 
                   ncol = ncol(filtereddata))
colnames(predSens) <- paste(":", names(filtereddata), sep = "")
rownames(predSens) <- names(filtereddata)
predSens["y",] <- c(0, 1, 1, 0, 0, 0)# we also want to use time and age to predict the unobserved part.
results <- data.frame()
for (intercept in c(-5, -2, 0, 2, 5)) {
  for (deltaage in c(-1, -0.5, 0, 0.5, 1)) {
    for (deltatime in c(-1, -0.5, 0, 0.5, 1)) {
      res <- getimputationsummary(data = filtereddata,
                           intercept = intercept, 
                           deltaage = deltaage, 
                           deltatime = deltatime, 
                           formula = predMatrix,#the observable part
                           predSens = predSens,
                           sensFormula = sensFormula, #unobservable part
                           m = 10)
      results <- rbind(results,res)
    }
  }
}

save(results, file = "data/resultssensitivity.Rdata")
```


```{r echo=FALSE, eval=file.exists("data/resultssensitivity.Rdata")}
load("data/resultssensitivitywithlearning.Rdata")
```

```{r resultsintercept, echo=FALSE, fig.cap="Sensitivity analysis of the effect on the estimated intercept and the 95 percent confidence intervals. The rows show different values for deltage. The columns show different values for deltatime. The confidence intervals are less bright if the confidence interval entails zero.", fig.width = 8, fig.height = 8}
appendertime <- function(string) 
    TeX(paste("$\\delta_{Ytime} = $", string))  
appenderage <- function(string) 
    TeX(paste("$\\delta_{Yage} = $", string)) 
results %>% filter(term == "(Intercept)") %>%
  mutate(term = str_remove(term, "_discrete"),
         significant = (p.value < 0.05)) %>%
  ggplot() +
  geom_line(aes(x = intercept, y = estimate, color = term)) +
  geom_point(aes(x = intercept, y = estimate, color = term, 
                 alpha = significant)) +
  geom_errorbar(aes(x = intercept, ymin = ub, ymax = lb, color = term, 
                    alpha = significant), 
                position = position_dodge(0.1)) +
  geom_hline(aes(yintercept = 0)) + 
  facet_grid(rows = vars(deltaage),
             cols = vars(deltatime),
             labeller = labeller(
               .rows = as_labeller(appenderage,
                                   default = label_parsed),
               .cols = as_labeller(appendertime, 
                                   default = label_parsed))) + 
  theme_bw() + theme(legend.position = "bottom") + 
  scale_alpha_discrete(range = c(0.3,1)) + 
  xlab(TeX(r'($\delta_{Y0}$)')) + 
  scale_x_continuous(breaks = c(-5, -2, 0, 2, 5))
```

```{r resultssens,echo=FALSE, fig.cap="Sensitivity analysis of the effect on all parameter estimates, except for the intercept. The rows show different values for deltage. The columns show different values for deltatime. The 95 percent confidence intervals are less bright if the confidence interval entails zero." , fig.width = 8, fig.height = 8}
results %>% filter(term != "(Intercept)") %>%
  mutate(term = str_remove(str_remove(term, "_discrete"),"TRUE"),
         significant = (p.value < 0.05)) %>%
  ggplot() +
  geom_line(aes(x=intercept, y = estimate, color = term)) +
  geom_point(aes(x = intercept, y = estimate, color = term, 
                 alpha = significant)) +
  geom_errorbar(aes(x = intercept, ymin = ub, ymax = lb, color = term, 
                    alpha = significant), 
                position = position_dodge(0.1)) +
  geom_hline(aes(yintercept = 0)) + 
  facet_grid(rows = vars(deltaage),
             cols = vars(deltatime),
             labeller = labeller(
               .rows = as_labeller(appenderage,
                                   default = label_parsed),
               .cols = as_labeller(appendertime, 
                                   default = label_parsed))) + 
  theme_bw() + theme(legend.position = "bottom") + 
  scale_alpha_discrete(range = c(0.3,1)) + 
  xlab(TeX(r'($\delta_{Y0}$)')) + 
  scale_x_continuous(breaks = c(-5, -2, 0, 2, 5))
```

```{r include = FALSE}
interceptchange <- results %>%
  group_by(deltatime, deltaage, term) %>%
  summarize(diffintercept = max(estimate) - min(estimate)) %>%
  ungroup()
```

Figure \@ref(fig:resultsintercept) shows the estimated intercepts and \@ref(fig:resultssens) shows all other parameter estimates. 

A shift in the intercept for imputed data ($\delta_{Y0}$) of 1 dB results in an almost equal shift in the estimated intercept from the gee model (`r round(mean(unlist(interceptchange[interceptchange$term == "(Intercept)","diffintercept"]))/10,2)` dB). This was expected because such a large part of the data is imputed. It is, however, more interesting to look at the other parameter estimates. Figure \@ref(fig:resultssens2) shows the effects on the different variables even clearer. 

The parameter estimate for age is usually negative, except when $\delta_{Y0}$, $\delta_{Ytime}$ and $\delta_{Yage}$ are all very negative. The interaction effect between time and age is always positive when $\delta_{Y0} >=0$ and negative or insignificant if $\delta_{Y0}<0$. The parameter estimate for $age^2$ is usually positive, unless all three $\delta$'s become negative. The learning effect is the largest of all and it is mainly impacted by $\delta_{Y0}$. The parameter estimate for TIME does not seem very impacted by $\delta_{Ytime}$ or $\delta_{Y0}$ but it is very sensitive to changes in $\delta_{Yage}$.

```{r resultssens2,echo=FALSE, fig.cap= "Heatmap for all parameter estimates, except for the intercept. The rows show the different parameters (covariates). The columns show different values for deltatime." , fig.width = 8, fig.height = 8}
results %>% filter(term != "(Intercept)") %>%
  mutate(term = str_remove(str_remove(term, "_discrete"),"TRUE"),
         significant = (p.value < 0.05),
         color = ifelse(significant,
                        ifelse(estimate>0, "positive","negative"),
                        "not significant")) %>%
  ggplot() +
  geom_tile(aes(color = color, fill = color, alpha = abs(estimate), x = intercept, y= deltaage)) +
  geom_hline(aes(yintercept = 0)) + 
  facet_grid(rows = vars(term),
             cols = vars(deltatime),,
             labeller = labeller(
               .cols = as_labeller(appendertime, 
                                   default = label_parsed))) + 
  theme_bw() + theme(legend.position = "bottom") + 
  scale_fill_manual(name = "", breaks = c("positive","not significant", "negative" ),
                      values = c('green','grey','red')) + 
  scale_color_manual(name = "", breaks = c("positive","not significant", "negative" ),
                      values = c('forestgreen','grey','red')) + 
  xlab(TeX(r'($\delta_{Y0}$)')) + 
  ylab(TeX(r'($\delta_{Yage}$)')) + 
  scale_x_continuous(breaks = c(-5, -2, 0, 2, 5)) + guides(alpha = "none") 
```

# Conclusion

The hearing threshold dataset it very unbalanced and a lot of data is missing. Therefore, one needs to be very careful when interpreting models that are fit on the incomplete data. 

Both direct likelihood methods and general estimating equations with and without multiple imputation are tested on the data. Generally, all models still confirm that subjects loose hearing as time passes and as the get older, regardless of the imputation method. There is also still some support for a learning effect meaning subjects seem to have worse hearing the first time they undergo the test, as was also observed in previous literature.

Any violation of MAR may have a significant impact on the model estimates, as shown in the sensitivity analysis.

# Future research

```{r include = FALSE}
#calculate missingness if time scale is every two years
test <- data_grid %>%
  mutate(TIME_discrete = ifelse(TIME_discrete %% 2 == 0,
                                TIME_discrete,
                                TIME_discrete - 1)) %>%
  group_by(id, TIME_discrete) %>%
  summarize(y = ifelse(sum(!is.na(y)) == 0,
                       NA,
                       max(y, na.rm = T))) %>%
  ungroup()
missingperc <- sum(is.na(test$y))/nrow(test)
#link to author paper prof molenberghs
#https://documentserver.uhasselt.be/bitstream/1942/33320/2/CIS-MI-MLR-2020.09.22.09.00.pdf
```
It might be useful to replicated the current analysis but with a coarser time frame. In this report, time was discretized by rounding down the time for each measurement. That resulted in 23 time instances (year 0 until year 22) and a lot of missing data since many subjects return, on average, around every two years (81.8% missingness Figure \@ref(fig:Missingness)). Changing the time scale to $\{0, 2, 4, ..., 22\}$ yields only 12 time instances and decreases missingness to `r round(100*missingperc,2)`% and the missingness comes closer to monotone missingness.

The sensitivity analysis using NARFCS may also be improved upon because there exist many other MNAR sensitivity analyses that may yield different insights [see for instance @uranga2022multiple ; @de2017comparison]. A downside of NARFCS, for instance, is that the sensitivity parameters are conditional parameters. THey represent differences in the distribution of the observed and missing values of each variable, *conditional* on the other variables, and *conditional* on the missingness indicators of the other variables. These parameters are therefor essentially impossible to elicit directly from experts, and differs from the marginal difference between the observed and missing values for the variable. This means that choosing values for the conditional sensitivity parameters involved in NARFCS is tricky.

# Bibliography

