---
documentclass: article
fontsize: 12pt
date: "`r Sys.Date()`"
output: 
  bookdown::pdf_document2: 
    toc: false
    latex_engine: xelatex
    fig_caption: yes
    includes:
      in_header: preamble.sty
      before_body: titlepage.sty
bibliography: references.bib  
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(haven) # to read SAS files
library(kableExtra)
library(qwraps2)
library(rprojroot)
library(patchwork)
library(psych)
library(gtools)
library(ordinal)
library(visdat)#visualize missingness
library(mice)
knitr::opts_chunk$set(echo = TRUE)
```

```{r load, include=FALSE, message=FALSE, warning=FALSE}
trichotomization <- c(-100, 6, 25, 120)
data <- read_sas(find_root_file("data/hearing500lr.sas7bdat",
                                criterion = has_file("LDA.Rproj"))) %>%
  mutate(side = as.factor(side),
         side_integer = as.integer(side),
         TIME_discrete = round(TIME),
         id = as.factor(id),
         id_integer = as.integer(id),
         age_measurement = age + TIME,
         age_scale = unname(scale(age, center = TRUE, scale = TRUE)),
         age_discrete = cut(age,
                            breaks = c(0,30,50,70,100),
                            labels = c("<30", "30-50", "50-70",">70")),
         y_discrete = factor(as.factor(cut(y,
                          breaks = trichotomization,
                          labels = c("Excellent", "Normal", "Hearing loss"))),
                          levels = c("Excellent", "Normal", "Hearing loss"),
                          ordered = TRUE),
         y_integer = as.integer(y_discrete),
         learning = 1*(TIME == 0)) %>%
  arrange(id)
subject_characteristics <- data %>%
  group_by(id) %>%
  summarize(age = first(age),
            age_scale = first(age_scale),
            age_discrete = first(age_discrete),
            id_integer = first(id_integer)) %>%
  ungroup()
  
data_grid <- expand.grid(id = unique(data$id),
                         TIME_discrete = 0:max(data$TIME_discrete),
                         side = unique(data$side)) %>%
  left_join(data %>% dplyr::select(-age, -age_scale, -age_discrete, 
                                   -id_integer)) %>%
  mutate(R = is.na(y), # R denotes missingness
         learning = (TIME_discrete == 0)) %>%
  left_join(subject_characteristics, by = c("id" = "id")) #add the subject characteristics back in)
```

# Introduction

This report assesses the evolution of hearing thresholds over time for a sample of `r nlevels(data$id)` healthy male volunteers. The data originates from the famous Baltimore Longitudinal Study of Aging (BLSA). Previous research showed a change in hearing threshold for all age groups but especially the older population [@doi:10.1121/1.399731]. In this report, we will especially take care of missingness in the data.

First, the *TIME* variable is rounded to the nearest integer value. As such, we aim to balance the dataset with equally-spaced time instances when hearing thresholds are measured. 

Hearing thresholds will be explored, both as a continuous variable and as a trichotomized (ordinal) variable with the following three levels:

- $\leq$ 6 dB: Excellent hearing
- over 6 and $\leq$ 25 dB: Normal hearing
- $\geq$ 26 dB: Hearing loss

## Missingness exploration
```{r Missingnessprep, include=FALSE, message=FALSE, warning=FALSE}
data_by_id_time <- data_grid %>% 
  group_by(id, TIME_discrete) %>%
  summarize(n = sum(!is.na(y_discrete))) %>%
  ungroup()
```

After discretizing the *TIME* variable, we consider a subject to be missing at a certain time instance if there is no measurement for that subject at that time. It should be noted that, if the subject is not missing (`r round((1-sum(data_by_id_time$n==0)/nrow(data_by_id_time))*100,2)`% of TIME-subject instances), we usually (`r round((sum(data_by_id_time$n==2)/nrow(data_by_id_time))*100,2)`% of TIME-subject instances) have two measurements (one for each ear) at each time instance. In fact, the average number of measurements per subject at each time instance is `r round(mean(data_by_id_time$n),2)`, and maximum `r round(max(data_by_id_time$n),2)`. 

Figure \@ref(fig:Missingness) was created using the *visdat* package. It shows all subjects, ordered from youngest (in the top) to oldest (in the bottom) and whether or not their data is missing at a certain time instance (on the x-axis). The percentages on top shows the percentage of missingness at each time instance. It is clear from Figure \@ref(fig:Missingness) that the missingness is not monotone; subjects may be missing at one time instance and come back later. Since there are too many possible missingness patterns with 23 time instances ($2^{23}$), we do not give an overview of the number of subjects that follow each possible pattern. Instead, figure \@ref(fig:missingnessovertime) shows, for each time instance, the number of subjects that:

- are *present*: when the subject's hearing is measured at time $t$ and $t-1$
- are *missing*: when the subject is missing at time $t$ and $t-1$
- *drop out*: when the subject's hearing is measured at time $t-1$ but not at time$t$
- *return*: when the subject's hearing is measured at time $t$ but not at time $t-1$

Figure \@ref(fig:missingnessovertime) clearly shows that subject rarely are measured two years in a row, most are not measured at $t=1$, and the number of subjects that stay missing gradually increases as time passes.

 
```{r Missingness, include=TRUE, echo = FALSE, message=FALSE, warning=FALSE, fig.cap = "Visual inspection of missingness for different ages at different time instances.", fig.height = 9, fig.width=7}
data_grid %>%
  mutate(TIME_discrete = factor(as.factor(TIME_discrete), ordered = TRUE)) %>%
  group_by(id, TIME_discrete) %>%
  summarize(missing = ifelse(any(!is.na(y)),TRUE, NA),
        age = first(age)) %>%
  ungroup() %>%
  pivot_wider(names_from = TIME_discrete, values_from = missing) %>% 
  arrange(age) %>%
  dplyr::select(3:(3 + max(data_grid$TIME_discrete))) %>%
  vis_miss() + ylab("id sorted by age") +
  theme(plot.margin = margin(0, 1, 0, 0, "cm")) 
```

```{r missingnessovertime, include=TRUE, echo = FALSE, message=FALSE, warning=FALSE, fig.cap = "Number of subjects the are present, return, drop out or are missing at each time instance.", fig.height = 4, fig.width=6}
categorize <- function(x){
  cat <- rep(NA, length(x))
  cat[1] <- ifelse(x[1], "missing", "present")
  if(length(x) > 1){
    l <- lag(x)
    cat[-1] <- ifelse(l[-1],
                      ifelse(x[-1],
                             "missing",
                             "return"),
                      ifelse(x[-1],
                             "drop out",
                             "present"))
  }
  return(cat)
}

data_grid %>%
  group_by(id, TIME_discrete) %>%
  summarize(R = any(R)) %>%
  ungroup() %>%
  group_by(id) %>%
  mutate(missing = factor(as.factor(categorize(R)), ordered = TRUE,
                          levels = c("present", "return", 
                          "drop out", "missing"))) %>%
  ungroup() %>%
  ggplot() +
  geom_bar(aes(x = TIME_discrete, fill = missing)) +
  scale_fill_discrete(name = "") +
  ylab("Number of subjects") + xlab("TIME") +
  theme_bw()
```

Lastly we explore whether the missingness can be explained by the data by fitting a mixed model to a dataset where $R_it$ is equal to one if the hearing threshold is missing and zero otherwise:

\begin{equation}
\left\{
                \begin{array}{ll}
                logit(R_{it}) = \beta_0 + \beta_1 TIME_{it} + \beta_3 side_{it} + \beta_4 age_{it} + \beta_5 R_{it-1} + b_i \\
                b_i \sim N(0,\sigma^2)
                \end{array}
          \right.
(\#eq:missingness)
\end{equation}

The variable *age* was standardized to get convergence in the model. Table \@ref(tab:missingmixedmodel) shows that TIME is significant; as time increases, subjects are more likely to be missing. We can therefore assume missingness at random (MAR). Left ear measurements are also more likely to be missing. A subject is also less likely to be missing at time $t$ if he was missing at time $t-1$. This can be seen especially in the first couple of years in figure \@ref(fig:Missingness): all but 3 subjects are measured at $t=0$, almost no-one is measured at $t=1$ and many are measured again at $t=2$.

```{r missingmixedmodel, include=TRUE, echo = FALSE, message=FALSE, warning=FALSE, eval=TRUE}
library(lme4)
data_grid <- data_grid %>% mutate(
  R_num = 1*(R == TRUE),
  age_scale = scale(age, center = TRUE, scale = TRUE)) %>%
  group_by(id) %>%
  mutate(R_num_lag = dplyr::lag(R_num, n = 1),
         y_last = tail(y[!is.na(y)],1)) %>%
  ungroup()
m1 <- glmer(formula = R_num ~ TIME_discrete + side + age_scale + R_num_lag + (1|id),
        data = data_grid,
        family = binomial(link = "logit"))
s <- summary(m1) 
s$coefficients %>% as.data.frame() %>%
  mutate(var = c('Intercept', "TIME", "sideright", "age", "$R_{t-1}$"),
         result = sprintf("%.2f %s", Estimate, stars.pval(`Pr(>|z|)`))) %>%
  dplyr::select(var, result) %>%
  rbind(c("sigma", round(unname(attr(s$varcor$id, "stddev"))^2,2))) %>%
  kable(booktabs = TRUE,
        caption = "A mixed model to predict missingness.",
        col.names = c('Variable', 'Estimate'),
        row.names = FALSE, 
        escape = FALSE) %>%
  kable_styling()
```


# Methodology

First, a direct likelihood analysis is compared with multiple imputation in the ?? continuous/discrete??? case. 
Next, weighted generalized estimating equations are compared with ‘multiple-imputation generalized estimating equations’. 
Lastly, a sensitivity analysis is performed.

For imputation, the *mice* library is used [@JSSv045i03] and different imputation techniques were tested: Predictive mean matching, Bayesian linear regression, Unconditional mean imputation, and imputation by random forests. 

All analysis was done in R. All scripts are freely available at [this git repository](https://github.com/raiisac/LDA). 

# Results

## Direct likelihood analysis versus multiple imputation

Q4

### Direct likelihood

### Multiple imputation



## Weighted generalized estimating equations versus ‘multiple-imputation generalized estimating equations’
Using frequentist methods,
Q5

## Sensitivity analysis

Q6

# Bibliography

