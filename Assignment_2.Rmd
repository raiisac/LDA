---
documentclass: article
fontsize: 12pt
date: "`r Sys.Date()`"
output: 
  bookdown::pdf_document2: 
    toc: false
    latex_engine: xelatex
    fig_caption: yes
    includes:
      in_header: preamble.sty
      before_body: titlepage.sty
bibliography: references.bib  
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(haven) # to read SAS files
library(kableExtra)
library(qwraps2)
library(rprojroot)
library(patchwork)
library(psych)
library(gtools)
library(ordinal)

knitr::opts_chunk$set(echo = TRUE)
```

```{r load, include=FALSE, message=FALSE, warning=FALSE}
trichotomization <- c(-100, 6, 25, 120)
data <- read_sas(find_root_file("data/hearing500lr.sas7bdat",
                                criterion = has_file("LDA.Rproj"))) %>%
  mutate(side = as.factor(side),
         side_integer = as.integer(side),
         TIME_scale = unname(scale(TIME, center = TRUE, scale = TRUE)),
         id = as.factor(id),
         id_integer = as.integer(id),
         age_measurement = age + TIME,
         age_scale = unname(scale(age, center = TRUE, scale = TRUE)),
         age_discrete = cut(age,
                            breaks = c(0,30,50,70,100),
                            labels = c("<30", "30-50", "50-70",">70")),
         y_discrete = factor(as.factor(cut(y,
                          breaks = trichotomization,
                          labels = c("Excellent", "Normal", "Hearing loss"))),
                          levels = c("Excellent", "Normal", "Hearing loss"),
                          ordered = TRUE),
         y_integer = as.integer(y_discrete),
         learning = 1*(TIME == 0)) %>%
  arrange(id)
mediansplit <- cut_number(data$y, n = 3)
```

# Data trichotomization

To trichotomize the data, suitable cut-off points need to be found. The cutoff points are often chosen based on either  expert knowledge or so as to optimize predictive power. An easy, often used method for dichotomization is a median-split since it assures that there are an equal amount of observation at either side of the cut-off value. Similarly, for trichotomization, we could aim for approximately 33.33% of the observations in each of the three categories. That would result in the following three categories: `r sprintf("%s, %s, %s",levels(mediansplit)[1],levels(mediansplit)[2],levels(mediansplit)[3])`.

It is quite common in literature to dichotomize hearing loss into normal hearing (\leq25 dB) and hearing loss (>25 dB) [see @garinis2017cumulative; @gallagher2019; @ju2022long, for example]. However, thichotomization is less common and it should be noted that it is generally not advised to discretize continuous data since some information is inevitably lost [@doi:10.1080/03610926.2016.1248783; @maccallum2002practice]. 

[The Centers for Disease Control and Prevention](https://www.cdc.gov/niosh/mining/userfiles/works/pdfs/2008-102.pdf) distinguishes the following levels of hearing loss, based on @clark1981:

- \leq 25 dB: Normal hearing
- 26 - 40 dB: Mild hearing loss
- 41 - 55 dB: Moderate hearing loss
- 56 - 70 dB: Moderate / severe hearing loss
- 71 - 90 dB: Severe hearing loss
- \geq 91 dB: Profound hearing loss


```{r clark, echo=FALSE, message = FALSE, fig.cap= "Hearing threshold over time, divided by left and right ear. The numbers in the bottom show the number of measurements that were taken.", fig.width = 5, fig.height=4}
data_clark <- data %>% mutate(
  y_clark = as.factor(cut(y, breaks = c(-13, 25, 40, 55, 56, 70, 90, 120)))
) %>%
  group_by(y_clark) %>%
  summarize(n = n(),
            n_id = n_distinct(id),
            avg_age = mean(age_measurement),
            nperc = n/nrow(data)*100) %>%
  ungroup() %>% 
  mutate(Cum = cumsum(n)/sum(n)*100) %>%
  dplyr::select(y_clark, n, nperc, Cum, n_id, avg_age) 
data_clark %>%
  kable(col.names = c("Category", "Nb observations", "Percentage", 
                      "Cumulative percentage", "Nb subjects", "Avg age"),
        caption = "Number of observations in each pre-defined categories from Clark (1981).",
        booktabs = TRUE,
        digits = 2) %>%
  kable_styling(latex_options = "HOLD_position")
```

Table \@ref(tab:clark) shows that, in this dataset, there is no one in the severe hearing loss categories and the large majority has normal hearing (`r round(data_clark[1, "nperc"],2)`%). The median for all observation with normal hearing (\leq 25dB) is 6 dB. We therefor suggest to trichotomize the data into the following categories:

- \leq 6 dB: Excellent hearing
- 7 - 25 dB: Normal hearing
- \geq 25 dB: Hearing loss

```{r ydiscrete, echo=FALSE, message = FALSE, fig.cap= "Hearing threshold over time, divided by left and right ear. The numbers in the bottom show the number of measurements that were taken.", fig.width = 5, fig.height=4}
data %>% 
  group_by(y_discrete) %>%
  summarize(n = n(),
            n_id = n_distinct(id),
            avg_age = mean(age_measurement),
            nperc = n/nrow(data)*100) %>%
  ungroup() %>% 
  mutate(Cum = cumsum(n)/sum(n)*100) %>%
  dplyr::select(y_discrete, n, nperc, Cum, n_id, avg_age) %>%
  kable(col.names = c("Category", "Nb observations", "Percentage", 
                      "Cumulative percentage", "Nb subjects", "Avg age"),
        caption = "Number of observations in each category.",
        booktabs = TRUE,
        digits = 2) %>%
  kable_styling(latex_options = "HOLD_position")
```

# Methodology
All analysis was done in R. All scripts are freely available at [this git repository](https://github.com/raiisac/LDA). 


# Results
## Marginal model
First, we fit a marginal model with the *ordLORgee* from the **multgee**. This function allows for an ordinal dependent variable which is appropriate for our data.

```{r loadgee, echo=FALSE, message = FALSE, warning = FALSE, eval = file.exists("Stefan RMD/fit.Rdata")}
#if the R object exists, load it to avoid long calculation times. If not, fit the model on the fly and same the object
library(multgee)
load("Stefan RMD/fit.Rdata")
```

```{r fitgee, echo=FALSE, message = FALSE, eval = !file.exists("Stefan RMD/fit.Rdata")}
#if the R object exists, load it to avoid long calculation times. If not, fit the model on the fly and same the object
library(multgee)
fit <- ordLORgee(formula = y_discrete ~ age*TIME + I(age^2) +learning,
                 link = "logit", id = id, data = data,
                 LORstr = "time.exch")#category.exch"
```

```{r geepredictions, echo=FALSE, message = FALSE, fig.width = 6, fig.height = 5}
agecat <- c(20,30,40,50,60,70)
nDF <- expand.grid(age = agecat,
                   TIME = seq(0, 22, length.out = 60)) %>%
  mutate(learning = (TIME == 0),
         `I(age^2)` = age^2,
         `age:TIME` = age*TIME)
#age:TIME is not yet in fit
```

## Random-effects model
The random effects model only includes a random intercept since it did not converge with random slopes included. 
```{r fitremod, echo=FALSE, message = FALSE, cache=TRUE}
remod <- clmm(y_discrete ~ age_scale*TIME + learning + I(age_scale^2) +
               (1|id_integer), #doesn't work with random slopes
             data = data)
# remod2 <- clmm2(y_discrete ~ age_scale*TIME + learning + I(age_scale^2),
#                 random = id_integer, #doesn't work with random slopes
#              data = data,
#              Hess = TRUE)
expit <- function(x){1/(1 + exp(-x))}
```

The random intercept has a variance (standard deviation) of `r round(remod$ST$id_integer[1]^2,2)` (`r round(remod$ST$id_integer[1],2)`).

```{r REpredictions, echo=FALSE, message = FALSE, fig.width = 6, fig.height = 5}
agecat <- c(20,30,40,50,60,70)
scaled_ages <- scale(agecat,
                       center = attr(data$age_scale,"scaled:center"),
                       scale = attr(data$age_scale,"scaled:scale"))[,1]
nDF <- expand.grid(age_scale = scaled_ages,
                   TIME = seq(0, 22, length.out = 60),
                   y_discrete = levels(data$y_discrete)) %>%
  mutate(learning = (TIME == 0),
         `I(age_scale^2)` = age_scale^2,
         `age_scale:TIME` = age_scale*TIME) %>%
  dplyr::select(y_discrete, names(coef(remod))[-c(1,2)]) 
#excellent|normal Note that it's beta[1] !-! SUM(other coefficients*covaraites) see expression (1) in https://cran.r-project.org/web/packages/ordinal/vignettes/clm_article.pdf
pred_excellent_normal_fixed <- as.numeric(coef(remod)[1]) -
                                 as.numeric(t(as.vector(coef(remod)[-c(1,2)])) %*%
                                 unlist(t(as.matrix(nDF[,-1]))))
#normal/hearing loss
pred_normal_hl_fixed <- as.numeric(coef(remod)[2]) -
                                 as.numeric(t(as.vector(coef(remod)[-c(1,2)])) %*%
                                 unlist(t(as.matrix(nDF[,-1]))))
#number of randomly drawn numbers
n <- 2000
randomnumbers <- rnorm(n, mean = 0, sd = remod$ST$id_integer[1])
nDF <- nDF %>%
  mutate(pred_excellent_normal_naive = expit(pred_excellent_normal_fixed),
         pred_excellent_normal = sapply(1:nrow(nDF), 
                                    FUN = function(x){
                                      mean(
                                        expit(
                                          pred_excellent_normal_fixed[x] +
                                            randomnumbers))}),
         pred_excellent_normal_error = sapply(1:nrow(nDF), 
                                    FUN = function(x){
                                      qnorm(0.975) * sd(
                                        expit(
                                          pred_excellent_normal_fixed[x] +
                                            randomnumbers)) / sqrt(n)}),
         pred_normal_hl_naive = expit(pred_normal_hl_fixed),
         pred_normal_hl = sapply(1:nrow(nDF), 
                                    FUN = function(x){
                                      mean(
                                        expit(
                                          pred_normal_hl_fixed[x] +
                                            randomnumbers))}),
         pred_normal_hl_error = sapply(1:nrow(nDF), 
                                    FUN = function(x){
                                      qnorm(0.975) * sd(
                                        expit(
                                          pred_normal_hl_fixed[x] +
                                            randomnumbers)) / sqrt(n)}),
         age = factor(as.factor(age_scale), levels = scaled_ages,
                      labels = agecat))
nDF %>% pivot_longer(cols = c(pred_excellent_normal_naive,
                              pred_excellent_normal,
                              pred_normal_hl_naive,
                              pred_normal_hl),
                     values_to = "Prediction",
                     names_to = "Type") %>%
  mutate(naive = str_detect(Type, "naive"),
         probability = ifelse(str_detect(Type, "normal_hl"),
                              "Normal|Hearing Loss",
                              "Excellent|Normal")) %>%
  ggplot() + geom_line(aes(y = Prediction,
                           x = TIME, group = interaction(Type, age),
                           color = age,
                           lty = probability,
                           alpha = naive)) +
  scale_alpha_manual(breaks = c(TRUE, FALSE), values = c(0.5, 1)) +
  ylim(0,1) + theme_bw()
```

```{r REmarginalpredictions, echo=FALSE, message = FALSE, fig.width = 6, fig.height = 5}
nDF %>%
  mutate(Excellent = pred_excellent_normal,
         Normal = pred_normal_hl - pred_excellent_normal,
         Hearingloss = 1 - pred_normal_hl) %>%
  pivot_longer(cols = c(Excellent, Normal, Hearingloss),
                     values_to = "Prediction",
                     names_to = "Type") %>%
  ggplot() + geom_line(aes(y = Prediction,
                           x = TIME, group = interaction(Type, age),
                           color = age,
                           lty = Type)) +
  ylim(0,1) + theme_bw()
```

### Empirical Bayes prediction
Q3

## Transition model
Q4

# Discussion


# Bibliography

